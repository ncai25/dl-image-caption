{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5OHaGch1U6m"
      },
      "source": [
        "# HW5: Image Captioning\n",
        "---\n",
        "\n",
        "This is the Notebook that goes with **Homework 5: Image Captioning**! \n",
        "\n",
        "In this notebook, you can run the assignments main method and train either the RNN or the Transformer model, instead of running the assignment on your personal machine. In addition, you can visualize the self-attention layer in your TransformerDecoder, and generate captions using both of your models for images in the test dataset. \n",
        "\n",
        "This notebook can be ported to Colab very quickly, so please feel free to try that out! It might also make some of the training quicker..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1gOuhXVXYQo"
      },
      "source": [
        "## Preparation Code\n",
        "\n",
        "If need be, feel free to pull your content from GitHub using this or a similar cell of choice. This should be moderately standard-practice for some of you. Additionally, remember to %cd to the required directories as needed for your workflow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AhGwcFfE7OnO"
      },
      "outputs": [],
      "source": [
        "# #@title Github Clone A Repository\n",
        "# #@markdown **NOTE**: Must use access token as password. To make one, go [here](https://github.com/settings/tokens) and save your token!\n",
        "\n",
        "# from IPython.display import clear_output\n",
        "# import sys, os\n",
        "\n",
        "# git_user_default = 'your-github-username'\n",
        "# git_user = 'your-github-username'  #@param {type:\"string\"}\n",
        "# if git_user == git_user_default:\n",
        "#   git_user = input(\"Enter your Github username: \")\n",
        "# parent_repo = 'Brown-Deep-Learning'\n",
        "# assignment_name = 'homework5_imagecaption'  #@param {type:\"string\"}\n",
        "# github_repo = f'{parent_repo}/{assignment_name}-{git_user}'\n",
        "# force_reclone = True           #@param {type:\"boolean\"}\n",
        "# is_private_repo = True            #@param {type:\"boolean\"}\n",
        "# keep_gh_login = True            #@param {type:\"boolean\"}\n",
        "\n",
        "# user_dir, github_dir = github_repo.split('/')\n",
        "# data_file = f'{github_dir}/hw5/data/data.p'\n",
        "\n",
        "# if not os.path.isdir(github_dir) or force_reclone:\n",
        "    \n",
        "#     if is_private_repo:\n",
        "#         if 'git_user' not in globals() or 'git_pass' not in globals():\n",
        "#             # git_user = input(\"Username: \")\n",
        "#             git_pass = input(\"GH Token: \")\n",
        "#             clear_output() \n",
        "\n",
        "#     if force_reclone:\n",
        "#         !rm -rf {github_dir} &> /dev/null\n",
        "\n",
        "#     if is_private_repo:\n",
        "#         !git clone https://{git_user}:{git_pass}@github.com/{github_repo}.git\n",
        "#         if not keep_gh_login:\n",
        "#             del git_user, git_pass \n",
        "#     else: \n",
        "#         !git clone https://github.com/{github_repo}.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvuKoBRGYAwf"
      },
      "source": [
        "This block of code imports the classes you completed in your assignment, along with additional libraries needed for the visualizations.\n",
        "\n",
        "Feel free to add autoimport queries as needed. This notebook's code will not be auto-ran by the autograder (only the outputs will be looked at during manual grading), so do what you need to here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ARiGr47j7T-I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from model import ImageCaptionModel\n",
        "from decoder import TransformerDecoder, RNNDecoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This assignment uses the Flickr 8k dataset! Let's go ahead and pull that in!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_captions:   (35455, 21)\n",
            "test_captions:    (5000, 21)\n",
            "\n",
            "train_img_feats:  (35455, 2048)\n",
            "test_img_feats:   (5000, 2048)\n",
            "\n",
            "train_images:     (500, 224, 224, 3)\n",
            "test_images:      (500, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "## Before this, download the dataset and run preprocessing.py as instructed. \n",
        "## This may take like 10 mins, but should only happen once so ok.\n",
        "## https://www.kaggle.com/datasets/adityajn105/flickr8k?resource=download\n",
        "\n",
        "with open('../data/data.p', 'rb') as data_file:\n",
        "    data_dict = pickle.load(data_file)\n",
        "\n",
        "# As mentioned in the handout, this assignment has 5 captions per image. This block of code \n",
        "# expands the image_feature lists to have 5 copies of each image to correspond to each of their captions \n",
        "feat_prep = lambda x: np.repeat(np.array(x).reshape(-1, 2048), 5, axis=0)\n",
        "img_prep  = lambda x: np.repeat(x, 5, axis=0)\n",
        "\n",
        "## Captions; preprocessed sentences with 20 window size\n",
        "train_captions  = np.array(data_dict['train_captions']);            print('train_captions:  ', train_captions.shape)\n",
        "test_captions   = np.array(data_dict['test_captions']);             print('test_captions:   ', test_captions.shape)\n",
        "\n",
        "## 2048-D resnet embeddings of images.\n",
        "train_img_feats = feat_prep(data_dict['train_image_features']);     print('\\ntrain_img_feats: ', train_img_feats.shape)\n",
        "test_img_feats  = feat_prep(data_dict['test_image_features']);      print('test_img_feats:  ', test_img_feats.shape)\n",
        "\n",
        "## Small subset of actual images for visualization purposes. \n",
        "## These are just for the first 100 images of each (clones 5 times)\n",
        "train_images    = img_prep(data_dict['train_images']);              print('\\ntrain_images:    ', train_images.shape)\n",
        "test_images     = img_prep(data_dict['test_images']);               print('test_images:     ', test_images.shape)\n",
        "\n",
        "## Conversion dictionaries to go between word and label index\n",
        "word2idx        = data_dict['word2idx']\n",
        "idx2word        = data_dict['idx2word']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the images take up a lot of data, we only kept a sliver of the original images. Feel free to update the preprocessing to retain all of the images if you'd like. Below is a visualization of some of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        print(f'Caption {j+1}:', ' '.join([idx2word[idx] for idx in train_captions[i * 5 + j]]))\n",
        "    plt.imshow(train_images[i * 5])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO0tgcqO77g1"
      },
      "source": [
        "## Training your model\n",
        "\n",
        "As always you can complete and run this assignments main method on your personal machine. However, you can also choose to run the assignment in this notebook to take advantage of Colab's GPU allocation! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iIKs4lo0iIo"
      },
      "source": [
        "### Running your RNN model\n",
        "\n",
        "Depending on your use cases, you may choose to structure your model in a variety of ways. In contrast to previous assignments, this one is intended to mimic a lot of modern research-oriented repositories you might find in the wild. Specifically: **Instead of providing easy-to-use APIs for experimenters, they rigidify their implementation to make tests replicable.** Specifically, they may provide a command-line interface and define testing/training procedures which log results. \n",
        "\n",
        "(I mean, ideally you can make a flexible API and allow for both ease of extension and examples to demonstrate how your results were gathered, but sometimes researchers only have so much time...)\n",
        "\n",
        "Once you have filled in the `model.py` components and the `RNNDecoder` of the `decoder.py` file, run this block to train your RNN model. As you can see, the hyperparamets default to the ones you use in `assignment.py`'s argparse specification, but feel free to change any of them to try to improve your model. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can investigate `assignment.py` to find that main will try to parse command-line arguments and fill in a variety of defaults. Specifically, you'll find this: \n",
        "```python\n",
        "def parse_args(args=None):\n",
        "    \"\"\" \n",
        "    Perform command-line argument parsing (other otherwise parse arguments with defaults). \n",
        "    To parse in an interative context (i.e. in notebook), add required arguments.\n",
        "    These will go into args and will generate a list that can be passed in.\n",
        "    For example: \n",
        "        parse_args('--type', 'rnn', ...)\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(...)\n",
        "    parser.add_argument('--type',           required=True,              ...)\n",
        "    parser.add_argument('--task',           required=True,              ...)\n",
        "    parser.add_argument('--data',           required=True,              ...')\n",
        "    parser.add_argument('--epochs',         type=int,   default=3,      ...)\n",
        "    parser.add_argument('--lr',             type=float, default=1e-3,   ...)\n",
        "    parser.add_argument('--optimizer',      type=str,   default='adam', ...)\n",
        "    parser.add_argument('--batch_size',     type=int,   default=100,    ...)\n",
        "    parser.add_argument('--hidden_size',    type=int,   default=256,    ...)\n",
        "    parser.add_argument('--window_size',    type=int,   default=20,     ...)\n",
        "    parser.add_argument('--chkpt_path',     default='',                 ...)\n",
        "    parser.add_argument('--check_valid',    default=True,               ...)\n",
        "    if args is None: \n",
        "        return parser.parse_args()      ## For calling through command line\n",
        "    return parser.parse_args(args)      ## For calling through notebook.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When trying to run the file by default, you'll get a nice usage error message if you are missing any required arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: assignment.py [-h] --type {rnn,transformer} --task {train,test,both}\n",
            "                     --data DATA [--epochs EPOCHS] [--lr LR]\n",
            "                     [--optimizer {adam,rmsprop,sgd}]\n",
            "                     [--batch_size BATCH_SIZE] [--hidden_size HIDDEN_SIZE]\n",
            "                     [--window_size WINDOW_SIZE] [--chkpt_path CHKPT_PATH]\n",
            "                     [--check_valid]\n",
            "assignment.py: error: the following arguments are required: --type, --task, --data\n"
          ]
        }
      ],
      "source": [
        "!python assignment.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows what kinds of arguments can be passed into your python file via main, and is reminiscent of what you might have seen in HW3. \n",
        "\n",
        "The following command will therefore be sufficient to try what an author (or you) might consider to be a \"default training run\" of the model: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IxtDkQEx8gcg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Valid 354/354]\t loss=3.763\t acc: 0.240\t perp: 43.082[[ 13  50  52 ...  16  16  16]\n",
            " [ 13 167  44 ...  16  16  16]\n",
            " [186 415  65 ...  16  16  16]\n",
            " ...\n",
            " [217 119 120 ...  16  16  16]\n",
            " [214 147   2 ...  16  16  16]\n",
            " [ 22 190 249 ...  16  16  16]]\n",
            "[Valid 1/50]\t loss=3.407\t acc: 0.274\t perp: 30.185[[214   2  92 ...  72  15  16]\n",
            " [ 17  79   2 ...  16  16  16]\n",
            " [ 17  79 157 ...  16  16  16]\n",
            " ...\n",
            " [  1   2  86 ...  16  16  16]\n",
            " [ 97   1   2 ...  16  16  16]\n",
            " [180   1  44 ...  16  16  16]]\n",
            "[Valid 2/50]\t loss=3.315\t acc: 0.279\t perp: 27.535[[ 86   1  44 ...  16  16  16]\n",
            " [  1   2  68 ...  16  16  16]\n",
            " [  1  11 461 ...  16  16  16]\n",
            " ...\n",
            " [462 421 558 ...  16  16  16]\n",
            " [ 13 307  44 ...  16  16  16]\n",
            " [462   2   3 ...  16  16  16]]\n",
            "[Valid 3/50]\t loss=3.277\t acc: 0.289\t perp: 26.489[[ 66  34 408 ...  16  16  16]\n",
            " [ 34  69   3 ...  16  16  16]\n",
            " [319 240  34 ...  16  16  16]\n",
            " ...\n",
            " [ 34   6  32 ...  16  16  16]\n",
            " [ 34 318   3 ...  16  16  16]\n",
            " [ 34  32  17 ...  16  16  16]]\n",
            "[Valid 4/50]\t loss=3.276\t acc: 0.288\t perp: 26.471[[147 138  65 ...  16  16  16]\n",
            " [532  44  60 ...  16  16  16]\n",
            " [436  65 424 ...  16  16  16]\n",
            " ...\n",
            " [ 17  79   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  73  79 ...  16  16  16]]\n",
            "[Valid 5/50]\t loss=3.253\t acc: 0.294\t perp: 25.869[[ 17  86 281 ...  16  16  16]\n",
            " [ 17  86 281 ...  96  11  15]\n",
            " [ 17  86 281 ...  16  16  16]\n",
            " ...\n",
            " [101  19 412 ...  16  16  16]\n",
            " [135 415 121 ...  16  16  16]\n",
            " [135 412 493 ...  16  16  16]]\n",
            "[Valid 6/50]\t loss=3.270\t acc: 0.295\t perp: 26.317[[ 37 159   3 ...  16  16  16]\n",
            " [ 37 208 415 ...  16  16  16]\n",
            " [ 37 337   1 ...  16  16  16]\n",
            " ...\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 95 307 221 ...  16  16  16]\n",
            " [ 28  50 221 ...  16  16  16]]\n",
            "[Valid 7/50]\t loss=3.256\t acc: 0.297\t perp: 25.953[[268  50   2 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  45 ...  16  16  16]\n",
            " ...\n",
            " [ 73 214  44 ...  16  16  16]\n",
            " [ 73 214   3 ...  16  16  16]\n",
            " [268 214  11 ...  16  16  16]]\n",
            "[Valid 8/50]\t loss=3.230\t acc: 0.296\t perp: 25.282[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 34  90 224 ...  16  16  16]\n",
            " ...\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]]\n",
            "[Valid 9/50]\t loss=3.229\t acc: 0.292\t perp: 25.260[[123  24 186 ...  16  16  16]\n",
            " [186 121 147 ...  16  16  16]\n",
            " [186 127 559 ...  16  16  16]\n",
            " ...\n",
            " [ 17  23 282 ...  16  16  16]\n",
            " [ 17  23  60 ...  16  16  16]\n",
            " [ 17   3  24 ...  16  16  16]]\n",
            "[Valid 10/50]\t loss=3.216\t acc: 0.295\t perp: 24.920[[214   2  68 ...  16  16  16]\n",
            " [307   2 226 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " ...\n",
            " [309   3 224 ...  16  16  16]\n",
            " [309 367 120 ...  16  16  16]\n",
            " [ 13 309  44 ...  16  16  16]]\n",
            "[Valid 11/50]\t loss=3.211\t acc: 0.295\t perp: 24.815[[ 50 154 389 ...  16  16  16]\n",
            " [130  19 101 ...  16  16  16]\n",
            " [ 13 370  46 ...  16  16  16]\n",
            " ...\n",
            " [101  19  23 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [ 23   2   3 ...  16  16  16]]\n",
            "[Valid 12/50]\t loss=3.216\t acc: 0.293\t perp: 24.921[[ 34  32  13 ...  16  16  16]\n",
            " [268  34  11 ...  16  16  16]\n",
            " [ 95  34  11 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 193 ...  16  16  16]\n",
            " [ 50   3  51 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]]\n",
            "[Valid 13/50]\t loss=3.224\t acc: 0.293\t perp: 25.120[[  3   3  40 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " ...\n",
            " [101  19  22 ...  16  16  16]\n",
            " [  3  71  22 ...  16  16  16]\n",
            " [  3   3 537 ...  16  16  16]]\n",
            "[Valid 14/50]\t loss=3.223\t acc: 0.292\t perp: 25.108[[192   3 104 ...  16  16  16]\n",
            " [  1  60  61 ...  16  16  16]\n",
            " [500 214   3 ...  16  16  16]\n",
            " ...\n",
            " [186  80 289 ...  16  16  16]\n",
            " [186  83 289 ...  16  16  16]\n",
            " [186 268  83 ...  16  16  16]]\n",
            "[Valid 15/50]\t loss=3.221\t acc: 0.291\t perp: 25.061[[214   2  61 ...  16  16  16]\n",
            " [214 227 215 ...  16  16  16]\n",
            " [366   2  61 ...  16  16  16]\n",
            " ...\n",
            " [217  90   3 ...  16  16  16]\n",
            " [217 367   3 ...  16  16  16]\n",
            " [217  96 171 ...  16  16  16]]\n",
            "[Valid 16/50]\t loss=3.223\t acc: 0.291\t perp: 25.113[[101  19 281 ...  16  16  16]\n",
            " [  3  19 281 ...  16  16  16]\n",
            " [135 281  24 ...  16  16  16]\n",
            " ...\n",
            " [101  19 404 ...  16  16  16]\n",
            " [240 101  19 ...  16  16  16]\n",
            " [  3 599   3 ...  16  16  16]]\n",
            "[Valid 17/50]\t loss=3.226\t acc: 0.292\t perp: 25.178[[ 17  79  24 ...  16  16  16]\n",
            " [ 17  79  24 ...  16  16  16]\n",
            " [ 17 204  96 ...  16  16  16]\n",
            " ...\n",
            " [  1  44   3 ...  16  16  16]\n",
            " [139  44 467 ...  16  16  16]\n",
            " [139   3 487 ...  16  16  16]]\n",
            "[Valid 18/50]\t loss=3.223\t acc: 0.292\t perp: 25.094[[267  86  46 ...  16  16  16]\n",
            " [ 66  34  44 ...  16  16  16]\n",
            " [ 66  34  93 ...  16  16  16]\n",
            " ...\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]]\n",
            "[Valid 19/50]\t loss=3.218\t acc: 0.292\t perp: 24.978[[ 50  44 134 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  11 ... 143 472  15]\n",
            " ...\n",
            " [186  22   3 ...  16  16  16]\n",
            " [ 17  22 201 ...  16  16  16]\n",
            " [ 17 127  46 ...  16  16  16]]\n",
            "[Valid 20/50]\t loss=3.226\t acc: 0.291\t perp: 25.168[[  1  46 215 ...  16  16  16]\n",
            " [  1 119 189 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [339 307  44 ...  16  16  16]\n",
            " [ 73 214  87 ...  16  16  16]\n",
            " [ 73 214 131 ...  16  16  16]]\n",
            "[Valid 21/50]\t loss=3.220\t acc: 0.290\t perp: 25.035[[  1   2 240 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " [  1  69   3 ...  16  16  16]\n",
            " ...\n",
            " [186  22  24 ...  16  16  16]\n",
            " [186  22  24 ... 457  15  16]\n",
            " [186  22   2 ...  16  16  16]]\n",
            "[Valid 22/50]\t loss=3.215\t acc: 0.292\t perp: 24.905[[ 34  52 237 ...  16  16  16]\n",
            " [ 34  32 351 ...  16  16  16]\n",
            " [ 34 279  32 ...  16  16  16]\n",
            " ...\n",
            " [ 95 214   2 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " [123  44 268 ...  16  16  16]]\n",
            "[Valid 23/50]\t loss=3.214\t acc: 0.292\t perp: 24.879[[135   3 289 ...  16  16  16]\n",
            " [135   3  32 ...  16  16  16]\n",
            " [ 13 135   3 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 95  50   3 ...  16  16  16]\n",
            " [ 13  50   2 ...  16  16  16]]\n",
            "[Valid 24/50]\t loss=3.218\t acc: 0.292\t perp: 24.974[[  1   3  11 ...  16  16  16]\n",
            " [  1   3  40 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [ 17 267 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]\n",
            " [ 17 281   2 ...  16  16  16]]\n",
            "[Valid 25/50]\t loss=3.214\t acc: 0.293\t perp: 24.885[[  1  47 248 ...  16  16  16]\n",
            " [217 119   3 ...  16  16  16]\n",
            " [217  44 227 ...  16  16  16]\n",
            " ...\n",
            " [214   2 153 ...  16  16  16]\n",
            " [307  84 142 ...  16  16  16]\n",
            " [ 73 214 495 ...  16  16  16]]\n",
            "[Valid 26/50]\t loss=3.214\t acc: 0.292\t perp: 24.880[[  1  44   3 ...  16  16  16]\n",
            " [  1 408  32 ...  16  16  16]\n",
            " [  1 205   2 ...  16  16  16]\n",
            " ...\n",
            " [440 361   3 ...  16  16  16]\n",
            " [366 365 120 ...  16  16  16]\n",
            " [549 214  32 ...  16  16  16]]\n",
            "[Valid 27/50]\t loss=3.221\t acc: 0.291\t perp: 25.055[[101  19 121 ...  16  16  16]\n",
            " [  3  60  62 ...  16  16  16]\n",
            " [ 99   3   2 ...  16  16  16]\n",
            " ...\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17   3  19 ...  16  16  16]]\n",
            "[Valid 28/50]\t loss=3.226\t acc: 0.291\t perp: 25.168[[323  19  22 ...  16  16  16]\n",
            " [101  19  22 ...  16  16  16]\n",
            " [ 65  44 205 ...  16  16  16]\n",
            " ...\n",
            " [214  46 240 ...  16  16  16]\n",
            " [214  46  40 ...  16  16  16]\n",
            " [214   2  68 ...  16  16  16]]\n",
            "[Valid 29/50]\t loss=3.229\t acc: 0.291\t perp: 25.259[[ 50   2  61 ...  16  16  16]\n",
            " [ 50   2 200 ...  16  16  16]\n",
            " [ 50  44  96 ...  16  16  16]\n",
            " ...\n",
            " [240  86  34 ...  16  16  16]\n",
            " [ 95  86  46 ...  16  16  16]\n",
            " [ 86  34   3 ...  16  16  16]]\n",
            "[Valid 30/50]\t loss=3.218\t acc: 0.294\t perp: 24.982[[186  80   2 ...  16  16  16]\n",
            " [186  80   2 ...  16  16  16]\n",
            " [186  80 125 ...  16  16  16]\n",
            " ...\n",
            " [ 48 493  50 ...  16  16  16]\n",
            " [ 73  50  11 ...  16  16  16]\n",
            " [ 73  48 493 ...  16  16  16]]\n",
            "[Valid 31/50]\t loss=3.224\t acc: 0.292\t perp: 25.130[[214   3  54 ...  16  16  16]\n",
            " [242 217  44 ...  16  16  16]\n",
            " [  1 365 185 ...  16  16  16]\n",
            " ...\n",
            " [186 281   3 ...  16  16  16]\n",
            " [186 281 279 ...  16  16  16]\n",
            " [186 240 281 ...  16  16  16]]\n",
            "[Valid 32/50]\t loss=3.228\t acc: 0.291\t perp: 25.229[[ 34   3   3 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 33/50]\t loss=3.227\t acc: 0.291\t perp: 25.201[[ 17 415  80 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " ...\n",
            " [  1  45   3 ...  16  16  16]\n",
            " [  1  41   3 ...  16  16  16]\n",
            " [ 13   3   1 ...  16  16  16]]\n",
            "[Valid 34/50]\t loss=3.218\t acc: 0.292\t perp: 24.987[[214   2 114 ...  16  16  16]\n",
            " [ 95 214   3 ...  16  16  16]\n",
            " [ 73 214  32 ...  16  16  16]\n",
            " ...\n",
            " [ 34  96   8 ...  16  16  16]\n",
            " [ 13  86  46 ...  94  15  16]\n",
            " [ 13  34  93 ...  16  16  16]]\n",
            "[Valid 35/50]\t loss=3.219\t acc: 0.292\t perp: 25.006[[214 270 608 ...  16  16  16]\n",
            " [ 73 214 270 ...  16  16  16]\n",
            " [307  11 354 ...  16  16  16]\n",
            " ...\n",
            " [ 50  69  47 ...  16  16  16]\n",
            " [268  50  87 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 36/50]\t loss=3.215\t acc: 0.292\t perp: 24.907[[214   2  92 ...  16  16  16]\n",
            " [214  41  36 ...  16  16  16]\n",
            " [214  60 293 ...  16  16  16]\n",
            " ...\n",
            " [  1  46  65 ...  16  16  16]\n",
            " [ 17  22 320 ...  16  16  16]\n",
            " [ 17  22   3 ...  16  16  16]]\n",
            "[Valid 37/50]\t loss=3.214\t acc: 0.292\t perp: 24.879[[214   2  61 ...  16  16  16]\n",
            " [307  60  61 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [217   2  13 ...  16  16  16]\n",
            " [217 365 120 ...  16  16  16]\n",
            " [ 13 217  44 ...  16  16  16]]\n",
            "[Valid 38/50]\t loss=3.212\t acc: 0.292\t perp: 24.828[[ 66   3  34 ...  16  16  16]\n",
            " [388  66  34 ...  16  16  16]\n",
            " [  3  34 131 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 323 ...  16  16  16]\n",
            " [372  80   3 ...  16  16  16]\n",
            " [123  44  50 ...  15  16  16]]\n",
            "[Valid 39/50]\t loss=3.215\t acc: 0.291\t perp: 24.894[[ 34 131  11 ...  16  16  16]\n",
            " [  3   3   3 ...  16  16  16]\n",
            " [ 86  46 110 ...  16  16  16]\n",
            " ...\n",
            " [135   3 396 ...  16  16  16]\n",
            " [ 21   3   3 ...  16  16  16]\n",
            " [ 13 101  19 ...  16  16  16]]\n",
            "[Valid 40/50]\t loss=3.214\t acc: 0.291\t perp: 24.873[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " ...\n",
            " [268  50 245 ...  16  16  16]\n",
            " [ 95 307   2 ...  16  16  16]\n",
            " [462   3   8 ...  16  16  16]]\n",
            "[Valid 41/50]\t loss=3.211\t acc: 0.291\t perp: 24.810[[366  44 520 ...  16  16  16]\n",
            " [268 214  44 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [  3 149 378 ...  16  16  16]\n",
            " [186  22  31 ...  16  16  16]\n",
            " [186 174   3 ...  16  16  16]]\n",
            "[Valid 42/50]\t loss=3.213\t acc: 0.292\t perp: 24.864[[  1  87   3 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [ 13   3  44 ...  16  16  16]\n",
            " ...\n",
            " [268 214   2 ...  16  16  16]\n",
            " [ 13 268 214 ...  16  16  16]\n",
            " [180 214  44 ...  16  16  16]]\n",
            "[Valid 43/50]\t loss=3.212\t acc: 0.292\t perp: 24.820[[  3 274  41 ...  16  16  16]\n",
            " [  3  19   3 ...  16  16  16]\n",
            " [585  46 281 ...  16  16  16]\n",
            " ...\n",
            " [ 73   1  44 ...  16  16  16]\n",
            " [309   2 251 ...  16  16  16]\n",
            " [309 253 254 ...  16  16  16]]\n",
            "[Valid 44/50]\t loss=3.211\t acc: 0.291\t perp: 24.797[[  1  44  87 ...  16  16  16]\n",
            " [  1 131   3 ...  16  16  16]\n",
            " [  1 164 134 ...  16  16  16]\n",
            " ...\n",
            " [192 590   3 ...  16  16  16]\n",
            " [ 22  46  34 ...  16  16  16]\n",
            " [189  22  46 ...  16  16  16]]\n",
            "[Valid 45/50]\t loss=3.215\t acc: 0.291\t perp: 24.892[[  1  60  92 ...  16  16  16]\n",
            " [139   2  92 ...  16  16  16]\n",
            " [309   2  92 ...  16  16  16]\n",
            " ...\n",
            " [ 95 323   2 ...  16  16  16]\n",
            " [ 95 323 164 ...  16  16  16]\n",
            " [ 22 144 137 ...  16  16  16]]\n",
            "[Valid 46/50]\t loss=3.216\t acc: 0.291\t perp: 24.920[[ 50   2   3 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 73  50  60 ...  16  16  16]\n",
            " ...\n",
            " [  3  44   3 ...  16  16  16]\n",
            " [110  34  44 ...  16  16  16]\n",
            " [110  34   6 ...  16  16  16]]\n",
            "[Valid 47/50]\t loss=3.215\t acc: 0.291\t perp: 24.892[[139   3  44 ...  16  16  16]\n",
            " [ 65   3   8 ...  16  16  16]\n",
            " [ 65  32 114 ...  16  16  16]\n",
            " ...\n",
            " [273 241  52 ...  16  16  16]\n",
            " [273 241   2 ...  16  16  16]\n",
            " [123  44   3 ...  16  16  16]]\n",
            "[Valid 48/50]\t loss=3.214\t acc: 0.292\t perp: 24.874[[101  19 204 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [  3 566 131 ...  16  16  16]\n",
            " ...\n",
            " [  1   2 269 ...  16  16  16]\n",
            " [  1  87  11 ...  16  16  16]\n",
            " [ 13  34  44 ...  16  16  16]]\n",
            "[Valid 49/50]\t loss=3.215\t acc: 0.292\t perp: 24.895[[101  19  80 ...  16  16  16]\n",
            " [101  19  73 ...  16  16  16]\n",
            " [  3  83 396 ...  16  16  16]\n",
            " ...\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]]\n",
            "[Valid 50/50]\t loss=3.212\t acc: 0.292\t perp: 24.820\n",
            "[Valid 354/354]\t loss=3.016\t acc: 0.318\t perp: 20.399[[ 13  50  52 ...  16  16  16]\n",
            " [ 13 167  44 ...  16  16  16]\n",
            " [186 415  65 ...  16  16  16]\n",
            " ...\n",
            " [217 119 120 ...  16  16  16]\n",
            " [214 147   2 ...  16  16  16]\n",
            " [ 22 190 249 ...  16  16  16]]\n",
            "[Valid 1/50]\t loss=3.199\t acc: 0.291\t perp: 24.520[[214   2  92 ...  72  15  16]\n",
            " [ 17  79   2 ...  16  16  16]\n",
            " [ 17  79 157 ...  16  16  16]\n",
            " ...\n",
            " [  1   2  86 ...  16  16  16]\n",
            " [ 97   1   2 ...  16  16  16]\n",
            " [180   1  44 ...  16  16  16]]\n",
            "[Valid 2/50]\t loss=3.100\t acc: 0.300\t perp: 22.200[[ 86   1  44 ...  16  16  16]\n",
            " [  1   2  68 ...  16  16  16]\n",
            " [  1  11 461 ...  16  16  16]\n",
            " ...\n",
            " [462 421 558 ...  16  16  16]\n",
            " [ 13 307  44 ...  16  16  16]\n",
            " [462   2   3 ...  16  16  16]]\n",
            "[Valid 3/50]\t loss=3.078\t acc: 0.309\t perp: 21.719[[ 66  34 408 ...  16  16  16]\n",
            " [ 34  69   3 ...  16  16  16]\n",
            " [319 240  34 ...  16  16  16]\n",
            " ...\n",
            " [ 34   6  32 ...  16  16  16]\n",
            " [ 34 318   3 ...  16  16  16]\n",
            " [ 34  32  17 ...  16  16  16]]\n",
            "[Valid 4/50]\t loss=3.048\t acc: 0.312\t perp: 21.063[[147 138  65 ...  16  16  16]\n",
            " [532  44  60 ...  16  16  16]\n",
            " [436  65 424 ...  16  16  16]\n",
            " ...\n",
            " [ 17  79   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  73  79 ...  16  16  16]]\n",
            "[Valid 5/50]\t loss=3.038\t acc: 0.315\t perp: 20.854[[ 17  86 281 ...  16  16  16]\n",
            " [ 17  86 281 ...  96  11  15]\n",
            " [ 17  86 281 ...  16  16  16]\n",
            " ...\n",
            " [101  19 412 ...  16  16  16]\n",
            " [135 415 121 ...  16  16  16]\n",
            " [135 412 493 ...  16  16  16]]\n",
            "[Valid 6/50]\t loss=3.059\t acc: 0.314\t perp: 21.308[[ 37 159   3 ...  16  16  16]\n",
            " [ 37 208 415 ...  16  16  16]\n",
            " [ 37 337   1 ...  16  16  16]\n",
            " ...\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 95 307 221 ...  16  16  16]\n",
            " [ 28  50 221 ...  16  16  16]]\n",
            "[Valid 7/50]\t loss=3.043\t acc: 0.318\t perp: 20.965[[268  50   2 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  45 ...  16  16  16]\n",
            " ...\n",
            " [ 73 214  44 ...  16  16  16]\n",
            " [ 73 214   3 ...  16  16  16]\n",
            " [268 214  11 ...  16  16  16]]\n",
            "[Valid 8/50]\t loss=3.017\t acc: 0.321\t perp: 20.421[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 34  90 224 ...  16  16  16]\n",
            " ...\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]]\n",
            "[Valid 9/50]\t loss=3.011\t acc: 0.320\t perp: 20.309[[123  24 186 ...  16  16  16]\n",
            " [186 121 147 ...  16  16  16]\n",
            " [186 127 559 ...  16  16  16]\n",
            " ...\n",
            " [ 17  23 282 ...  16  16  16]\n",
            " [ 17  23  60 ...  16  16  16]\n",
            " [ 17   3  24 ...  16  16  16]]\n",
            "[Valid 10/50]\t loss=3.001\t acc: 0.321\t perp: 20.108[[214   2  68 ...  16  16  16]\n",
            " [307   2 226 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " ...\n",
            " [309   3 224 ...  16  16  16]\n",
            " [309 367 120 ...  16  16  16]\n",
            " [ 13 309  44 ...  16  16  16]]\n",
            "[Valid 11/50]\t loss=2.993\t acc: 0.322\t perp: 19.946[[ 50 154 389 ...  16  16  16]\n",
            " [130  19 101 ...  16  16  16]\n",
            " [ 13 370  46 ...  16  16  16]\n",
            " ...\n",
            " [101  19  23 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [ 23   2   3 ...  16  16  16]]\n",
            "[Valid 12/50]\t loss=3.000\t acc: 0.320\t perp: 20.087[[ 34  32  13 ...  16  16  16]\n",
            " [268  34  11 ...  16  16  16]\n",
            " [ 95  34  11 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 193 ...  16  16  16]\n",
            " [ 50   3  51 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]]\n",
            "[Valid 13/50]\t loss=3.010\t acc: 0.318\t perp: 20.289[[  3   3  40 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " ...\n",
            " [101  19  22 ...  16  16  16]\n",
            " [  3  71  22 ...  16  16  16]\n",
            " [  3   3 537 ...  16  16  16]]\n",
            "[Valid 14/50]\t loss=3.007\t acc: 0.318\t perp: 20.222[[192   3 104 ...  16  16  16]\n",
            " [  1  60  61 ...  16  16  16]\n",
            " [500 214   3 ...  16  16  16]\n",
            " ...\n",
            " [186  80 289 ...  16  16  16]\n",
            " [186  83 289 ...  16  16  16]\n",
            " [186 268  83 ...  16  16  16]]\n",
            "[Valid 15/50]\t loss=3.001\t acc: 0.319\t perp: 20.101[[214   2  61 ...  16  16  16]\n",
            " [214 227 215 ...  16  16  16]\n",
            " [366   2  61 ...  16  16  16]\n",
            " ...\n",
            " [217  90   3 ...  16  16  16]\n",
            " [217 367   3 ...  16  16  16]\n",
            " [217  96 171 ...  16  16  16]]\n",
            "[Valid 16/50]\t loss=3.000\t acc: 0.319\t perp: 20.080[[101  19 281 ...  16  16  16]\n",
            " [  3  19 281 ...  16  16  16]\n",
            " [135 281  24 ...  16  16  16]\n",
            " ...\n",
            " [101  19 404 ...  16  16  16]\n",
            " [240 101  19 ...  16  16  16]\n",
            " [  3 599   3 ...  16  16  16]]\n",
            "[Valid 17/50]\t loss=3.003\t acc: 0.319\t perp: 20.141[[ 17  79  24 ...  16  16  16]\n",
            " [ 17  79  24 ...  16  16  16]\n",
            " [ 17 204  96 ...  16  16  16]\n",
            " ...\n",
            " [  1  44   3 ...  16  16  16]\n",
            " [139  44 467 ...  16  16  16]\n",
            " [139   3 487 ...  16  16  16]]\n",
            "[Valid 18/50]\t loss=3.001\t acc: 0.321\t perp: 20.106[[267  86  46 ...  16  16  16]\n",
            " [ 66  34  44 ...  16  16  16]\n",
            " [ 66  34  93 ...  16  16  16]\n",
            " ...\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]]\n",
            "[Valid 19/50]\t loss=2.999\t acc: 0.321\t perp: 20.067[[ 50  44 134 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  11 ... 143 472  15]\n",
            " ...\n",
            " [186  22   3 ...  16  16  16]\n",
            " [ 17  22 201 ...  16  16  16]\n",
            " [ 17 127  46 ...  16  16  16]]\n",
            "[Valid 20/50]\t loss=3.003\t acc: 0.319\t perp: 20.153[[  1  46 215 ...  16  16  16]\n",
            " [  1 119 189 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [339 307  44 ...  16  16  16]\n",
            " [ 73 214  87 ...  16  16  16]\n",
            " [ 73 214 131 ...  16  16  16]]\n",
            "[Valid 21/50]\t loss=3.000\t acc: 0.320\t perp: 20.095[[  1   2 240 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " [  1  69   3 ...  16  16  16]\n",
            " ...\n",
            " [186  22  24 ...  16  16  16]\n",
            " [186  22  24 ... 457  15  16]\n",
            " [186  22   2 ...  16  16  16]]\n",
            "[Valid 22/50]\t loss=2.999\t acc: 0.321\t perp: 20.075[[ 34  52 237 ...  16  16  16]\n",
            " [ 34  32 351 ...  16  16  16]\n",
            " [ 34 279  32 ...  16  16  16]\n",
            " ...\n",
            " [ 95 214   2 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " [123  44 268 ...  16  16  16]]\n",
            "[Valid 23/50]\t loss=3.001\t acc: 0.321\t perp: 20.101[[135   3 289 ...  16  16  16]\n",
            " [135   3  32 ...  16  16  16]\n",
            " [ 13 135   3 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 95  50   3 ...  16  16  16]\n",
            " [ 13  50   2 ...  16  16  16]]\n",
            "[Valid 24/50]\t loss=3.004\t acc: 0.321\t perp: 20.164[[  1   3  11 ...  16  16  16]\n",
            " [  1   3  40 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [ 17 267 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]\n",
            " [ 17 281   2 ...  16  16  16]]\n",
            "[Valid 25/50]\t loss=3.000\t acc: 0.322\t perp: 20.078[[  1  47 248 ...  16  16  16]\n",
            " [217 119   3 ...  16  16  16]\n",
            " [217  44 227 ...  16  16  16]\n",
            " ...\n",
            " [214   2 153 ...  16  16  16]\n",
            " [307  84 142 ...  16  16  16]\n",
            " [ 73 214 495 ...  16  16  16]]\n",
            "[Valid 26/50]\t loss=2.998\t acc: 0.322\t perp: 20.036[[  1  44   3 ...  16  16  16]\n",
            " [  1 408  32 ...  16  16  16]\n",
            " [  1 205   2 ...  16  16  16]\n",
            " ...\n",
            " [440 361   3 ...  16  16  16]\n",
            " [366 365 120 ...  16  16  16]\n",
            " [549 214  32 ...  16  16  16]]\n",
            "[Valid 27/50]\t loss=3.003\t acc: 0.322\t perp: 20.156[[101  19 121 ...  16  16  16]\n",
            " [  3  60  62 ...  16  16  16]\n",
            " [ 99   3   2 ...  16  16  16]\n",
            " ...\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17   3  19 ...  16  16  16]]\n",
            "[Valid 28/50]\t loss=3.008\t acc: 0.322\t perp: 20.252[[323  19  22 ...  16  16  16]\n",
            " [101  19  22 ...  16  16  16]\n",
            " [ 65  44 205 ...  16  16  16]\n",
            " ...\n",
            " [214  46 240 ...  16  16  16]\n",
            " [214  46  40 ...  16  16  16]\n",
            " [214   2  68 ...  16  16  16]]\n",
            "[Valid 29/50]\t loss=3.009\t acc: 0.322\t perp: 20.270[[ 50   2  61 ...  16  16  16]\n",
            " [ 50   2 200 ...  16  16  16]\n",
            " [ 50  44  96 ...  16  16  16]\n",
            " ...\n",
            " [240  86  34 ...  16  16  16]\n",
            " [ 95  86  46 ...  16  16  16]\n",
            " [ 86  34   3 ...  16  16  16]]\n",
            "[Valid 30/50]\t loss=2.997\t acc: 0.324\t perp: 20.016[[186  80   2 ...  16  16  16]\n",
            " [186  80   2 ...  16  16  16]\n",
            " [186  80 125 ...  16  16  16]\n",
            " ...\n",
            " [ 48 493  50 ...  16  16  16]\n",
            " [ 73  50  11 ...  16  16  16]\n",
            " [ 73  48 493 ...  16  16  16]]\n",
            "[Valid 31/50]\t loss=3.003\t acc: 0.323\t perp: 20.144[[214   3  54 ...  16  16  16]\n",
            " [242 217  44 ...  16  16  16]\n",
            " [  1 365 185 ...  16  16  16]\n",
            " ...\n",
            " [186 281   3 ...  16  16  16]\n",
            " [186 281 279 ...  16  16  16]\n",
            " [186 240 281 ...  16  16  16]]\n",
            "[Valid 32/50]\t loss=3.007\t acc: 0.322\t perp: 20.235[[ 34   3   3 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 33/50]\t loss=3.006\t acc: 0.322\t perp: 20.201[[ 17 415  80 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " ...\n",
            " [  1  45   3 ...  16  16  16]\n",
            " [  1  41   3 ...  16  16  16]\n",
            " [ 13   3   1 ...  16  16  16]]\n",
            "[Valid 34/50]\t loss=2.998\t acc: 0.323\t perp: 20.039[[214   2 114 ...  16  16  16]\n",
            " [ 95 214   3 ...  16  16  16]\n",
            " [ 73 214  32 ...  16  16  16]\n",
            " ...\n",
            " [ 34  96   8 ...  16  16  16]\n",
            " [ 13  86  46 ...  94  15  16]\n",
            " [ 13  34  93 ...  16  16  16]]\n",
            "[Valid 35/50]\t loss=2.998\t acc: 0.322\t perp: 20.049[[214 270 608 ...  16  16  16]\n",
            " [ 73 214 270 ...  16  16  16]\n",
            " [307  11 354 ...  16  16  16]\n",
            " ...\n",
            " [ 50  69  47 ...  16  16  16]\n",
            " [268  50  87 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 36/50]\t loss=2.995\t acc: 0.323\t perp: 19.982[[214   2  92 ...  16  16  16]\n",
            " [214  41  36 ...  16  16  16]\n",
            " [214  60 293 ...  16  16  16]\n",
            " ...\n",
            " [  1  46  65 ...  16  16  16]\n",
            " [ 17  22 320 ...  16  16  16]\n",
            " [ 17  22   3 ...  16  16  16]]\n",
            "[Valid 37/50]\t loss=2.995\t acc: 0.323\t perp: 19.983[[214   2  61 ...  16  16  16]\n",
            " [307  60  61 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [217   2  13 ...  16  16  16]\n",
            " [217 365 120 ...  16  16  16]\n",
            " [ 13 217  44 ...  16  16  16]]\n",
            "[Valid 38/50]\t loss=2.993\t acc: 0.323\t perp: 19.946[[ 66   3  34 ...  16  16  16]\n",
            " [388  66  34 ...  16  16  16]\n",
            " [  3  34 131 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 323 ...  16  16  16]\n",
            " [372  80   3 ...  16  16  16]\n",
            " [123  44  50 ...  15  16  16]]\n",
            "[Valid 39/50]\t loss=2.995\t acc: 0.322\t perp: 19.977[[ 34 131  11 ...  16  16  16]\n",
            " [  3   3   3 ...  16  16  16]\n",
            " [ 86  46 110 ...  16  16  16]\n",
            " ...\n",
            " [135   3 396 ...  16  16  16]\n",
            " [ 21   3   3 ...  16  16  16]\n",
            " [ 13 101  19 ...  16  16  16]]\n",
            "[Valid 40/50]\t loss=2.992\t acc: 0.322\t perp: 19.933[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " ...\n",
            " [268  50 245 ...  16  16  16]\n",
            " [ 95 307   2 ...  16  16  16]\n",
            " [462   3   8 ...  16  16  16]]\n",
            "[Valid 41/50]\t loss=2.989\t acc: 0.322\t perp: 19.871[[366  44 520 ...  16  16  16]\n",
            " [268 214  44 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [  3 149 378 ...  16  16  16]\n",
            " [186  22  31 ...  16  16  16]\n",
            " [186 174   3 ...  16  16  16]]\n",
            "[Valid 42/50]\t loss=2.992\t acc: 0.321\t perp: 19.930[[  1  87   3 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [ 13   3  44 ...  16  16  16]\n",
            " ...\n",
            " [268 214   2 ...  16  16  16]\n",
            " [ 13 268 214 ...  16  16  16]\n",
            " [180 214  44 ...  16  16  16]]\n",
            "[Valid 43/50]\t loss=2.993\t acc: 0.321\t perp: 19.937[[  3 274  41 ...  16  16  16]\n",
            " [  3  19   3 ...  16  16  16]\n",
            " [585  46 281 ...  16  16  16]\n",
            " ...\n",
            " [ 73   1  44 ...  16  16  16]\n",
            " [309   2 251 ...  16  16  16]\n",
            " [309 253 254 ...  16  16  16]]\n",
            "[Valid 44/50]\t loss=2.992\t acc: 0.321\t perp: 19.923[[  1  44  87 ...  16  16  16]\n",
            " [  1 131   3 ...  16  16  16]\n",
            " [  1 164 134 ...  16  16  16]\n",
            " ...\n",
            " [192 590   3 ...  16  16  16]\n",
            " [ 22  46  34 ...  16  16  16]\n",
            " [189  22  46 ...  16  16  16]]\n",
            "[Valid 45/50]\t loss=2.995\t acc: 0.321\t perp: 19.977[[  1  60  92 ...  16  16  16]\n",
            " [139   2  92 ...  16  16  16]\n",
            " [309   2  92 ...  16  16  16]\n",
            " ...\n",
            " [ 95 323   2 ...  16  16  16]\n",
            " [ 95 323 164 ...  16  16  16]\n",
            " [ 22 144 137 ...  16  16  16]]\n",
            "[Valid 46/50]\t loss=2.996\t acc: 0.321\t perp: 20.000[[ 50   2   3 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 73  50  60 ...  16  16  16]\n",
            " ...\n",
            " [  3  44   3 ...  16  16  16]\n",
            " [110  34  44 ...  16  16  16]\n",
            " [110  34   6 ...  16  16  16]]\n",
            "[Valid 47/50]\t loss=2.995\t acc: 0.321\t perp: 19.982[[139   3  44 ...  16  16  16]\n",
            " [ 65   3   8 ...  16  16  16]\n",
            " [ 65  32 114 ...  16  16  16]\n",
            " ...\n",
            " [273 241  52 ...  16  16  16]\n",
            " [273 241   2 ...  16  16  16]\n",
            " [123  44   3 ...  16  16  16]]\n",
            "[Valid 48/50]\t loss=2.995\t acc: 0.321\t perp: 19.983[[101  19 204 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [  3 566 131 ...  16  16  16]\n",
            " ...\n",
            " [  1   2 269 ...  16  16  16]\n",
            " [  1  87  11 ...  16  16  16]\n",
            " [ 13  34  44 ...  16  16  16]]\n",
            "[Valid 49/50]\t loss=2.996\t acc: 0.321\t perp: 20.001[[101  19  80 ...  16  16  16]\n",
            " [101  19  73 ...  16  16  16]\n",
            " [  3  83 396 ...  16  16  16]\n",
            " ...\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]]\n",
            "[Valid 50/50]\t loss=2.993\t acc: 0.322\t perp: 19.937\n",
            "[Valid 354/354]\t loss=2.805\t acc: 0.345\t perp: 16.530[[ 13  50  52 ...  16  16  16]\n",
            " [ 13 167  44 ...  16  16  16]\n",
            " [186 415  65 ...  16  16  16]\n",
            " ...\n",
            " [217 119 120 ...  16  16  16]\n",
            " [214 147   2 ...  16  16  16]\n",
            " [ 22 190 249 ...  16  16  16]]\n",
            "[Valid 1/50]\t loss=3.114\t acc: 0.300\t perp: 22.513[[214   2  92 ...  72  15  16]\n",
            " [ 17  79   2 ...  16  16  16]\n",
            " [ 17  79 157 ...  16  16  16]\n",
            " ...\n",
            " [  1   2  86 ...  16  16  16]\n",
            " [ 97   1   2 ...  16  16  16]\n",
            " [180   1  44 ...  16  16  16]]\n",
            "[Valid 2/50]\t loss=3.004\t acc: 0.319\t perp: 20.157[[ 86   1  44 ...  16  16  16]\n",
            " [  1   2  68 ...  16  16  16]\n",
            " [  1  11 461 ...  16  16  16]\n",
            " ...\n",
            " [462 421 558 ...  16  16  16]\n",
            " [ 13 307  44 ...  16  16  16]\n",
            " [462   2   3 ...  16  16  16]]\n",
            "[Valid 3/50]\t loss=2.985\t acc: 0.328\t perp: 19.794[[ 66  34 408 ...  16  16  16]\n",
            " [ 34  69   3 ...  16  16  16]\n",
            " [319 240  34 ...  16  16  16]\n",
            " ...\n",
            " [ 34   6  32 ...  16  16  16]\n",
            " [ 34 318   3 ...  16  16  16]\n",
            " [ 34  32  17 ...  16  16  16]]\n",
            "[Valid 4/50]\t loss=2.953\t acc: 0.327\t perp: 19.171[[147 138  65 ...  16  16  16]\n",
            " [532  44  60 ...  16  16  16]\n",
            " [436  65 424 ...  16  16  16]\n",
            " ...\n",
            " [ 17  79   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  73  79 ...  16  16  16]]\n",
            "[Valid 5/50]\t loss=2.944\t acc: 0.328\t perp: 18.996[[ 17  86 281 ...  16  16  16]\n",
            " [ 17  86 281 ...  96  11  15]\n",
            " [ 17  86 281 ...  16  16  16]\n",
            " ...\n",
            " [101  19 412 ...  16  16  16]\n",
            " [135 415 121 ...  16  16  16]\n",
            " [135 412 493 ...  16  16  16]]\n",
            "[Valid 6/50]\t loss=2.964\t acc: 0.329\t perp: 19.369[[ 37 159   3 ...  16  16  16]\n",
            " [ 37 208 415 ...  16  16  16]\n",
            " [ 37 337   1 ...  16  16  16]\n",
            " ...\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 95 307 221 ...  16  16  16]\n",
            " [ 28  50 221 ...  16  16  16]]\n",
            "[Valid 7/50]\t loss=2.952\t acc: 0.332\t perp: 19.138[[268  50   2 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  45 ...  16  16  16]\n",
            " ...\n",
            " [ 73 214  44 ...  16  16  16]\n",
            " [ 73 214   3 ...  16  16  16]\n",
            " [268 214  11 ...  16  16  16]]\n",
            "[Valid 8/50]\t loss=2.927\t acc: 0.335\t perp: 18.663[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 34  90 224 ...  16  16  16]\n",
            " ...\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]]\n",
            "[Valid 9/50]\t loss=2.920\t acc: 0.332\t perp: 18.548[[123  24 186 ...  16  16  16]\n",
            " [186 121 147 ...  16  16  16]\n",
            " [186 127 559 ...  16  16  16]\n",
            " ...\n",
            " [ 17  23 282 ...  16  16  16]\n",
            " [ 17  23  60 ...  16  16  16]\n",
            " [ 17   3  24 ...  16  16  16]]\n",
            "[Valid 10/50]\t loss=2.911\t acc: 0.331\t perp: 18.382[[214   2  68 ...  16  16  16]\n",
            " [307   2 226 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " ...\n",
            " [309   3 224 ...  16  16  16]\n",
            " [309 367 120 ...  16  16  16]\n",
            " [ 13 309  44 ...  16  16  16]]\n",
            "[Valid 11/50]\t loss=2.902\t acc: 0.333\t perp: 18.211[[ 50 154 389 ...  16  16  16]\n",
            " [130  19 101 ...  16  16  16]\n",
            " [ 13 370  46 ...  16  16  16]\n",
            " ...\n",
            " [101  19  23 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [ 23   2   3 ...  16  16  16]]\n",
            "[Valid 12/50]\t loss=2.911\t acc: 0.332\t perp: 18.379[[ 34  32  13 ...  16  16  16]\n",
            " [268  34  11 ...  16  16  16]\n",
            " [ 95  34  11 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 193 ...  16  16  16]\n",
            " [ 50   3  51 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]]\n",
            "[Valid 13/50]\t loss=2.920\t acc: 0.331\t perp: 18.537[[  3   3  40 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " ...\n",
            " [101  19  22 ...  16  16  16]\n",
            " [  3  71  22 ...  16  16  16]\n",
            " [  3   3 537 ...  16  16  16]]\n",
            "[Valid 14/50]\t loss=2.918\t acc: 0.332\t perp: 18.497[[192   3 104 ...  16  16  16]\n",
            " [  1  60  61 ...  16  16  16]\n",
            " [500 214   3 ...  16  16  16]\n",
            " ...\n",
            " [186  80 289 ...  16  16  16]\n",
            " [186  83 289 ...  16  16  16]\n",
            " [186 268  83 ...  16  16  16]]\n",
            "[Valid 15/50]\t loss=2.912\t acc: 0.332\t perp: 18.397[[214   2  61 ...  16  16  16]\n",
            " [214 227 215 ...  16  16  16]\n",
            " [366   2  61 ...  16  16  16]\n",
            " ...\n",
            " [217  90   3 ...  16  16  16]\n",
            " [217 367   3 ...  16  16  16]\n",
            " [217  96 171 ...  16  16  16]]\n",
            "[Valid 16/50]\t loss=2.911\t acc: 0.332\t perp: 18.371[[101  19 281 ...  16  16  16]\n",
            " [  3  19 281 ...  16  16  16]\n",
            " [135 281  24 ...  16  16  16]\n",
            " ...\n",
            " [101  19 404 ...  16  16  16]\n",
            " [240 101  19 ...  16  16  16]\n",
            " [  3 599   3 ...  16  16  16]]\n",
            "[Valid 17/50]\t loss=2.915\t acc: 0.332\t perp: 18.445[[ 17  79  24 ...  16  16  16]\n",
            " [ 17  79  24 ...  16  16  16]\n",
            " [ 17 204  96 ...  16  16  16]\n",
            " ...\n",
            " [  1  44   3 ...  16  16  16]\n",
            " [139  44 467 ...  16  16  16]\n",
            " [139   3 487 ...  16  16  16]]\n",
            "[Valid 18/50]\t loss=2.915\t acc: 0.333\t perp: 18.444[[267  86  46 ...  16  16  16]\n",
            " [ 66  34  44 ...  16  16  16]\n",
            " [ 66  34  93 ...  16  16  16]\n",
            " ...\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]]\n",
            "[Valid 19/50]\t loss=2.913\t acc: 0.333\t perp: 18.406[[ 50  44 134 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  11 ... 143 472  15]\n",
            " ...\n",
            " [186  22   3 ...  16  16  16]\n",
            " [ 17  22 201 ...  16  16  16]\n",
            " [ 17 127  46 ...  16  16  16]]\n",
            "[Valid 20/50]\t loss=2.914\t acc: 0.331\t perp: 18.434[[  1  46 215 ...  16  16  16]\n",
            " [  1 119 189 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [339 307  44 ...  16  16  16]\n",
            " [ 73 214  87 ...  16  16  16]\n",
            " [ 73 214 131 ...  16  16  16]]\n",
            "[Valid 21/50]\t loss=2.912\t acc: 0.331\t perp: 18.390[[  1   2 240 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " [  1  69   3 ...  16  16  16]\n",
            " ...\n",
            " [186  22  24 ...  16  16  16]\n",
            " [186  22  24 ... 457  15  16]\n",
            " [186  22   2 ...  16  16  16]]\n",
            "[Valid 22/50]\t loss=2.911\t acc: 0.332\t perp: 18.366[[ 34  52 237 ...  16  16  16]\n",
            " [ 34  32 351 ...  16  16  16]\n",
            " [ 34 279  32 ...  16  16  16]\n",
            " ...\n",
            " [ 95 214   2 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " [123  44 268 ...  16  16  16]]\n",
            "[Valid 23/50]\t loss=2.912\t acc: 0.331\t perp: 18.401[[135   3 289 ...  16  16  16]\n",
            " [135   3  32 ...  16  16  16]\n",
            " [ 13 135   3 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 95  50   3 ...  16  16  16]\n",
            " [ 13  50   2 ...  16  16  16]]\n",
            "[Valid 24/50]\t loss=2.917\t acc: 0.331\t perp: 18.480[[  1   3  11 ...  16  16  16]\n",
            " [  1   3  40 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [ 17 267 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]\n",
            " [ 17 281   2 ...  16  16  16]]\n",
            "[Valid 25/50]\t loss=2.912\t acc: 0.331\t perp: 18.395[[  1  47 248 ...  16  16  16]\n",
            " [217 119   3 ...  16  16  16]\n",
            " [217  44 227 ...  16  16  16]\n",
            " ...\n",
            " [214   2 153 ...  16  16  16]\n",
            " [307  84 142 ...  16  16  16]\n",
            " [ 73 214 495 ...  16  16  16]]\n",
            "[Valid 26/50]\t loss=2.909\t acc: 0.331\t perp: 18.335[[  1  44   3 ...  16  16  16]\n",
            " [  1 408  32 ...  16  16  16]\n",
            " [  1 205   2 ...  16  16  16]\n",
            " ...\n",
            " [440 361   3 ...  16  16  16]\n",
            " [366 365 120 ...  16  16  16]\n",
            " [549 214  32 ...  16  16  16]]\n",
            "[Valid 27/50]\t loss=2.914\t acc: 0.330\t perp: 18.438[[101  19 121 ...  16  16  16]\n",
            " [  3  60  62 ...  16  16  16]\n",
            " [ 99   3   2 ...  16  16  16]\n",
            " ...\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17   3  19 ...  16  16  16]]\n",
            "[Valid 28/50]\t loss=2.919\t acc: 0.330\t perp: 18.530[[323  19  22 ...  16  16  16]\n",
            " [101  19  22 ...  16  16  16]\n",
            " [ 65  44 205 ...  16  16  16]\n",
            " ...\n",
            " [214  46 240 ...  16  16  16]\n",
            " [214  46  40 ...  16  16  16]\n",
            " [214   2  68 ...  16  16  16]]\n",
            "[Valid 29/50]\t loss=2.921\t acc: 0.330\t perp: 18.556[[ 50   2  61 ...  16  16  16]\n",
            " [ 50   2 200 ...  16  16  16]\n",
            " [ 50  44  96 ...  16  16  16]\n",
            " ...\n",
            " [240  86  34 ...  16  16  16]\n",
            " [ 95  86  46 ...  16  16  16]\n",
            " [ 86  34   3 ...  16  16  16]]\n",
            "[Valid 30/50]\t loss=2.909\t acc: 0.332\t perp: 18.338[[186  80   2 ...  16  16  16]\n",
            " [186  80   2 ...  16  16  16]\n",
            " [186  80 125 ...  16  16  16]\n",
            " ...\n",
            " [ 48 493  50 ...  16  16  16]\n",
            " [ 73  50  11 ...  16  16  16]\n",
            " [ 73  48 493 ...  16  16  16]]\n",
            "[Valid 31/50]\t loss=2.913\t acc: 0.332\t perp: 18.421[[214   3  54 ...  16  16  16]\n",
            " [242 217  44 ...  16  16  16]\n",
            " [  1 365 185 ...  16  16  16]\n",
            " ...\n",
            " [186 281   3 ...  16  16  16]\n",
            " [186 281 279 ...  16  16  16]\n",
            " [186 240 281 ...  16  16  16]]\n",
            "[Valid 32/50]\t loss=2.917\t acc: 0.331\t perp: 18.482[[ 34   3   3 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 33/50]\t loss=2.914\t acc: 0.331\t perp: 18.438[[ 17 415  80 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " ...\n",
            " [  1  45   3 ...  16  16  16]\n",
            " [  1  41   3 ...  16  16  16]\n",
            " [ 13   3   1 ...  16  16  16]]\n",
            "[Valid 34/50]\t loss=2.906\t acc: 0.332\t perp: 18.275[[214   2 114 ...  16  16  16]\n",
            " [ 95 214   3 ...  16  16  16]\n",
            " [ 73 214  32 ...  16  16  16]\n",
            " ...\n",
            " [ 34  96   8 ...  16  16  16]\n",
            " [ 13  86  46 ...  94  15  16]\n",
            " [ 13  34  93 ...  16  16  16]]\n",
            "[Valid 35/50]\t loss=2.906\t acc: 0.331\t perp: 18.285[[214 270 608 ...  16  16  16]\n",
            " [ 73 214 270 ...  16  16  16]\n",
            " [307  11 354 ...  16  16  16]\n",
            " ...\n",
            " [ 50  69  47 ...  16  16  16]\n",
            " [268  50  87 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 36/50]\t loss=2.901\t acc: 0.332\t perp: 18.198[[214   2  92 ...  16  16  16]\n",
            " [214  41  36 ...  16  16  16]\n",
            " [214  60 293 ...  16  16  16]\n",
            " ...\n",
            " [  1  46  65 ...  16  16  16]\n",
            " [ 17  22 320 ...  16  16  16]\n",
            " [ 17  22   3 ...  16  16  16]]\n",
            "[Valid 37/50]\t loss=2.901\t acc: 0.332\t perp: 18.192[[214   2  61 ...  16  16  16]\n",
            " [307  60  61 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [217   2  13 ...  16  16  16]\n",
            " [217 365 120 ...  16  16  16]\n",
            " [ 13 217  44 ...  16  16  16]]\n",
            "[Valid 38/50]\t loss=2.898\t acc: 0.333\t perp: 18.133[[ 66   3  34 ...  16  16  16]\n",
            " [388  66  34 ...  16  16  16]\n",
            " [  3  34 131 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 323 ...  16  16  16]\n",
            " [372  80   3 ...  16  16  16]\n",
            " [123  44  50 ...  15  16  16]]\n",
            "[Valid 39/50]\t loss=2.900\t acc: 0.332\t perp: 18.168[[ 34 131  11 ...  16  16  16]\n",
            " [  3   3   3 ...  16  16  16]\n",
            " [ 86  46 110 ...  16  16  16]\n",
            " ...\n",
            " [135   3 396 ...  16  16  16]\n",
            " [ 21   3   3 ...  16  16  16]\n",
            " [ 13 101  19 ...  16  16  16]]\n",
            "[Valid 40/50]\t loss=2.898\t acc: 0.332\t perp: 18.132[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " ...\n",
            " [268  50 245 ...  16  16  16]\n",
            " [ 95 307   2 ...  16  16  16]\n",
            " [462   3   8 ...  16  16  16]]\n",
            "[Valid 41/50]\t loss=2.894\t acc: 0.333\t perp: 18.071[[366  44 520 ...  16  16  16]\n",
            " [268 214  44 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [  3 149 378 ...  16  16  16]\n",
            " [186  22  31 ...  16  16  16]\n",
            " [186 174   3 ...  16  16  16]]\n",
            "[Valid 42/50]\t loss=2.898\t acc: 0.333\t perp: 18.133[[  1  87   3 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [ 13   3  44 ...  16  16  16]\n",
            " ...\n",
            " [268 214   2 ...  16  16  16]\n",
            " [ 13 268 214 ...  16  16  16]\n",
            " [180 214  44 ...  16  16  16]]\n",
            "[Valid 43/50]\t loss=2.897\t acc: 0.333\t perp: 18.125[[  3 274  41 ...  16  16  16]\n",
            " [  3  19   3 ...  16  16  16]\n",
            " [585  46 281 ...  16  16  16]\n",
            " ...\n",
            " [ 73   1  44 ...  16  16  16]\n",
            " [309   2 251 ...  16  16  16]\n",
            " [309 253 254 ...  16  16  16]]\n",
            "[Valid 44/50]\t loss=2.896\t acc: 0.332\t perp: 18.108[[  1  44  87 ...  16  16  16]\n",
            " [  1 131   3 ...  16  16  16]\n",
            " [  1 164 134 ...  16  16  16]\n",
            " ...\n",
            " [192 590   3 ...  16  16  16]\n",
            " [ 22  46  34 ...  16  16  16]\n",
            " [189  22  46 ...  16  16  16]]\n",
            "[Valid 45/50]\t loss=2.899\t acc: 0.332\t perp: 18.148[[  1  60  92 ...  16  16  16]\n",
            " [139   2  92 ...  16  16  16]\n",
            " [309   2  92 ...  16  16  16]\n",
            " ...\n",
            " [ 95 323   2 ...  16  16  16]\n",
            " [ 95 323 164 ...  16  16  16]\n",
            " [ 22 144 137 ...  16  16  16]]\n",
            "[Valid 46/50]\t loss=2.900\t acc: 0.332\t perp: 18.172[[ 50   2   3 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 73  50  60 ...  16  16  16]\n",
            " ...\n",
            " [  3  44   3 ...  16  16  16]\n",
            " [110  34  44 ...  16  16  16]\n",
            " [110  34   6 ...  16  16  16]]\n",
            "[Valid 47/50]\t loss=2.900\t acc: 0.332\t perp: 18.167[[139   3  44 ...  16  16  16]\n",
            " [ 65   3   8 ...  16  16  16]\n",
            " [ 65  32 114 ...  16  16  16]\n",
            " ...\n",
            " [273 241  52 ...  16  16  16]\n",
            " [273 241   2 ...  16  16  16]\n",
            " [123  44   3 ...  16  16  16]]\n",
            "[Valid 48/50]\t loss=2.900\t acc: 0.332\t perp: 18.168[[101  19 204 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [  3 566 131 ...  16  16  16]\n",
            " ...\n",
            " [  1   2 269 ...  16  16  16]\n",
            " [  1  87  11 ...  16  16  16]\n",
            " [ 13  34  44 ...  16  16  16]]\n",
            "[Valid 49/50]\t loss=2.901\t acc: 0.333\t perp: 18.195[[101  19  80 ...  16  16  16]\n",
            " [101  19  73 ...  16  16  16]\n",
            " [  3  83 396 ...  16  16  16]\n",
            " ...\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]]\n",
            "[Valid 50/50]\t loss=2.899\t acc: 0.333\t perp: 18.151\n",
            "[Valid 354/354]\t loss=2.673\t acc: 0.364\t perp: 14.482[[ 13  50  52 ...  16  16  16]\n",
            " [ 13 167  44 ...  16  16  16]\n",
            " [186 415  65 ...  16  16  16]\n",
            " ...\n",
            " [217 119 120 ...  16  16  16]\n",
            " [214 147   2 ...  16  16  16]\n",
            " [ 22 190 249 ...  16  16  16]]\n",
            "[Valid 1/50]\t loss=3.129\t acc: 0.313\t perp: 22.857[[214   2  92 ...  72  15  16]\n",
            " [ 17  79   2 ...  16  16  16]\n",
            " [ 17  79 157 ...  16  16  16]\n",
            " ...\n",
            " [  1   2  86 ...  16  16  16]\n",
            " [ 97   1   2 ...  16  16  16]\n",
            " [180   1  44 ...  16  16  16]]\n",
            "[Valid 2/50]\t loss=3.001\t acc: 0.323\t perp: 20.105[[ 86   1  44 ...  16  16  16]\n",
            " [  1   2  68 ...  16  16  16]\n",
            " [  1  11 461 ...  16  16  16]\n",
            " ...\n",
            " [462 421 558 ...  16  16  16]\n",
            " [ 13 307  44 ...  16  16  16]\n",
            " [462   2   3 ...  16  16  16]]\n",
            "[Valid 3/50]\t loss=2.979\t acc: 0.333\t perp: 19.659[[ 66  34 408 ...  16  16  16]\n",
            " [ 34  69   3 ...  16  16  16]\n",
            " [319 240  34 ...  16  16  16]\n",
            " ...\n",
            " [ 34   6  32 ...  16  16  16]\n",
            " [ 34 318   3 ...  16  16  16]\n",
            " [ 34  32  17 ...  16  16  16]]\n",
            "[Valid 4/50]\t loss=2.944\t acc: 0.332\t perp: 18.984[[147 138  65 ...  16  16  16]\n",
            " [532  44  60 ...  16  16  16]\n",
            " [436  65 424 ...  16  16  16]\n",
            " ...\n",
            " [ 17  79   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  73  79 ...  16  16  16]]\n",
            "[Valid 5/50]\t loss=2.931\t acc: 0.337\t perp: 18.739[[ 17  86 281 ...  16  16  16]\n",
            " [ 17  86 281 ...  96  11  15]\n",
            " [ 17  86 281 ...  16  16  16]\n",
            " ...\n",
            " [101  19 412 ...  16  16  16]\n",
            " [135 415 121 ...  16  16  16]\n",
            " [135 412 493 ...  16  16  16]]\n",
            "[Valid 6/50]\t loss=2.945\t acc: 0.339\t perp: 19.012[[ 37 159   3 ...  16  16  16]\n",
            " [ 37 208 415 ...  16  16  16]\n",
            " [ 37 337   1 ...  16  16  16]\n",
            " ...\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 95 307 221 ...  16  16  16]\n",
            " [ 28  50 221 ...  16  16  16]]\n",
            "[Valid 7/50]\t loss=2.927\t acc: 0.341\t perp: 18.680[[268  50   2 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  45 ...  16  16  16]\n",
            " ...\n",
            " [ 73 214  44 ...  16  16  16]\n",
            " [ 73 214   3 ...  16  16  16]\n",
            " [268 214  11 ...  16  16  16]]\n",
            "[Valid 8/50]\t loss=2.900\t acc: 0.343\t perp: 18.181[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 34  90 224 ...  16  16  16]\n",
            " ...\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]]\n",
            "[Valid 9/50]\t loss=2.888\t acc: 0.343\t perp: 17.966[[123  24 186 ...  16  16  16]\n",
            " [186 121 147 ...  16  16  16]\n",
            " [186 127 559 ...  16  16  16]\n",
            " ...\n",
            " [ 17  23 282 ...  16  16  16]\n",
            " [ 17  23  60 ...  16  16  16]\n",
            " [ 17   3  24 ...  16  16  16]]\n",
            "[Valid 10/50]\t loss=2.877\t acc: 0.345\t perp: 17.754[[214   2  68 ...  16  16  16]\n",
            " [307   2 226 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " ...\n",
            " [309   3 224 ...  16  16  16]\n",
            " [309 367 120 ...  16  16  16]\n",
            " [ 13 309  44 ...  16  16  16]]\n",
            "[Valid 11/50]\t loss=2.872\t acc: 0.343\t perp: 17.673[[ 50 154 389 ...  16  16  16]\n",
            " [130  19 101 ...  16  16  16]\n",
            " [ 13 370  46 ...  16  16  16]\n",
            " ...\n",
            " [101  19  23 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [ 23   2   3 ...  16  16  16]]\n",
            "[Valid 12/50]\t loss=2.883\t acc: 0.341\t perp: 17.872[[ 34  32  13 ...  16  16  16]\n",
            " [268  34  11 ...  16  16  16]\n",
            " [ 95  34  11 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 193 ...  16  16  16]\n",
            " [ 50   3  51 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]]\n",
            "[Valid 13/50]\t loss=2.895\t acc: 0.339\t perp: 18.078[[  3   3  40 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " ...\n",
            " [101  19  22 ...  16  16  16]\n",
            " [  3  71  22 ...  16  16  16]\n",
            " [  3   3 537 ...  16  16  16]]\n",
            "[Valid 14/50]\t loss=2.892\t acc: 0.340\t perp: 18.026[[192   3 104 ...  16  16  16]\n",
            " [  1  60  61 ...  16  16  16]\n",
            " [500 214   3 ...  16  16  16]\n",
            " ...\n",
            " [186  80 289 ...  16  16  16]\n",
            " [186  83 289 ...  16  16  16]\n",
            " [186 268  83 ...  16  16  16]]\n",
            "[Valid 15/50]\t loss=2.887\t acc: 0.340\t perp: 17.936[[214   2  61 ...  16  16  16]\n",
            " [214 227 215 ...  16  16  16]\n",
            " [366   2  61 ...  16  16  16]\n",
            " ...\n",
            " [217  90   3 ...  16  16  16]\n",
            " [217 367   3 ...  16  16  16]\n",
            " [217  96 171 ...  16  16  16]]\n",
            "[Valid 16/50]\t loss=2.887\t acc: 0.340\t perp: 17.933[[101  19 281 ...  16  16  16]\n",
            " [  3  19 281 ...  16  16  16]\n",
            " [135 281  24 ...  16  16  16]\n",
            " ...\n",
            " [101  19 404 ...  16  16  16]\n",
            " [240 101  19 ...  16  16  16]\n",
            " [  3 599   3 ...  16  16  16]]\n",
            "[Valid 17/50]\t loss=2.889\t acc: 0.340\t perp: 17.983[[ 17  79  24 ...  16  16  16]\n",
            " [ 17  79  24 ...  16  16  16]\n",
            " [ 17 204  96 ...  16  16  16]\n",
            " ...\n",
            " [  1  44   3 ...  16  16  16]\n",
            " [139  44 467 ...  16  16  16]\n",
            " [139   3 487 ...  16  16  16]]\n",
            "[Valid 18/50]\t loss=2.891\t acc: 0.340\t perp: 18.009[[267  86  46 ...  16  16  16]\n",
            " [ 66  34  44 ...  16  16  16]\n",
            " [ 66  34  93 ...  16  16  16]\n",
            " ...\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]]\n",
            "[Valid 19/50]\t loss=2.889\t acc: 0.340\t perp: 17.983[[ 50  44 134 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  11 ... 143 472  15]\n",
            " ...\n",
            " [186  22   3 ...  16  16  16]\n",
            " [ 17  22 201 ...  16  16  16]\n",
            " [ 17 127  46 ...  16  16  16]]\n",
            "[Valid 20/50]\t loss=2.891\t acc: 0.338\t perp: 18.018[[  1  46 215 ...  16  16  16]\n",
            " [  1 119 189 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [339 307  44 ...  16  16  16]\n",
            " [ 73 214  87 ...  16  16  16]\n",
            " [ 73 214 131 ...  16  16  16]]\n",
            "[Valid 21/50]\t loss=2.889\t acc: 0.338\t perp: 17.972[[  1   2 240 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " [  1  69   3 ...  16  16  16]\n",
            " ...\n",
            " [186  22  24 ...  16  16  16]\n",
            " [186  22  24 ... 457  15  16]\n",
            " [186  22   2 ...  16  16  16]]\n",
            "[Valid 22/50]\t loss=2.888\t acc: 0.339\t perp: 17.960[[ 34  52 237 ...  16  16  16]\n",
            " [ 34  32 351 ...  16  16  16]\n",
            " [ 34 279  32 ...  16  16  16]\n",
            " ...\n",
            " [ 95 214   2 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " [123  44 268 ...  16  16  16]]\n",
            "[Valid 23/50]\t loss=2.890\t acc: 0.338\t perp: 17.997[[135   3 289 ...  16  16  16]\n",
            " [135   3  32 ...  16  16  16]\n",
            " [ 13 135   3 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 95  50   3 ...  16  16  16]\n",
            " [ 13  50   2 ...  16  16  16]]\n",
            "[Valid 24/50]\t loss=2.895\t acc: 0.338\t perp: 18.080[[  1   3  11 ...  16  16  16]\n",
            " [  1   3  40 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [ 17 267 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]\n",
            " [ 17 281   2 ...  16  16  16]]\n",
            "[Valid 25/50]\t loss=2.890\t acc: 0.338\t perp: 17.992[[  1  47 248 ...  16  16  16]\n",
            " [217 119   3 ...  16  16  16]\n",
            " [217  44 227 ...  16  16  16]\n",
            " ...\n",
            " [214   2 153 ...  16  16  16]\n",
            " [307  84 142 ...  16  16  16]\n",
            " [ 73 214 495 ...  16  16  16]]\n",
            "[Valid 26/50]\t loss=2.886\t acc: 0.339\t perp: 17.922[[  1  44   3 ...  16  16  16]\n",
            " [  1 408  32 ...  16  16  16]\n",
            " [  1 205   2 ...  16  16  16]\n",
            " ...\n",
            " [440 361   3 ...  16  16  16]\n",
            " [366 365 120 ...  16  16  16]\n",
            " [549 214  32 ...  16  16  16]]\n",
            "[Valid 27/50]\t loss=2.892\t acc: 0.338\t perp: 18.029[[101  19 121 ...  16  16  16]\n",
            " [  3  60  62 ...  16  16  16]\n",
            " [ 99   3   2 ...  16  16  16]\n",
            " ...\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17   3  19 ...  16  16  16]]\n",
            "[Valid 28/50]\t loss=2.898\t acc: 0.336\t perp: 18.141[[323  19  22 ...  16  16  16]\n",
            " [101  19  22 ...  16  16  16]\n",
            " [ 65  44 205 ...  16  16  16]\n",
            " ...\n",
            " [214  46 240 ...  16  16  16]\n",
            " [214  46  40 ...  16  16  16]\n",
            " [214   2  68 ...  16  16  16]]\n",
            "[Valid 29/50]\t loss=2.900\t acc: 0.336\t perp: 18.166[[ 50   2  61 ...  16  16  16]\n",
            " [ 50   2 200 ...  16  16  16]\n",
            " [ 50  44  96 ...  16  16  16]\n",
            " ...\n",
            " [240  86  34 ...  16  16  16]\n",
            " [ 95  86  46 ...  16  16  16]\n",
            " [ 86  34   3 ...  16  16  16]]\n",
            "[Valid 30/50]\t loss=2.886\t acc: 0.339\t perp: 17.928[[186  80   2 ...  16  16  16]\n",
            " [186  80   2 ...  16  16  16]\n",
            " [186  80 125 ...  16  16  16]\n",
            " ...\n",
            " [ 48 493  50 ...  16  16  16]\n",
            " [ 73  50  11 ...  16  16  16]\n",
            " [ 73  48 493 ...  16  16  16]]\n",
            "[Valid 31/50]\t loss=2.892\t acc: 0.337\t perp: 18.024[[214   3  54 ...  16  16  16]\n",
            " [242 217  44 ...  16  16  16]\n",
            " [  1 365 185 ...  16  16  16]\n",
            " ...\n",
            " [186 281   3 ...  16  16  16]\n",
            " [186 281 279 ...  16  16  16]\n",
            " [186 240 281 ...  16  16  16]]\n",
            "[Valid 32/50]\t loss=2.895\t acc: 0.336\t perp: 18.089[[ 34   3   3 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 33/50]\t loss=2.893\t acc: 0.336\t perp: 18.048[[ 17 415  80 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " ...\n",
            " [  1  45   3 ...  16  16  16]\n",
            " [  1  41   3 ...  16  16  16]\n",
            " [ 13   3   1 ...  16  16  16]]\n",
            "[Valid 34/50]\t loss=2.884\t acc: 0.337\t perp: 17.881[[214   2 114 ...  16  16  16]\n",
            " [ 95 214   3 ...  16  16  16]\n",
            " [ 73 214  32 ...  16  16  16]\n",
            " ...\n",
            " [ 34  96   8 ...  16  16  16]\n",
            " [ 13  86  46 ...  94  15  16]\n",
            " [ 13  34  93 ...  16  16  16]]\n",
            "[Valid 35/50]\t loss=2.883\t acc: 0.337\t perp: 17.877[[214 270 608 ...  16  16  16]\n",
            " [ 73 214 270 ...  16  16  16]\n",
            " [307  11 354 ...  16  16  16]\n",
            " ...\n",
            " [ 50  69  47 ...  16  16  16]\n",
            " [268  50  87 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 36/50]\t loss=2.880\t acc: 0.338\t perp: 17.806[[214   2  92 ...  16  16  16]\n",
            " [214  41  36 ...  16  16  16]\n",
            " [214  60 293 ...  16  16  16]\n",
            " ...\n",
            " [  1  46  65 ...  16  16  16]\n",
            " [ 17  22 320 ...  16  16  16]\n",
            " [ 17  22   3 ...  16  16  16]]\n",
            "[Valid 37/50]\t loss=2.880\t acc: 0.337\t perp: 17.822[[214   2  61 ...  16  16  16]\n",
            " [307  60  61 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [217   2  13 ...  16  16  16]\n",
            " [217 365 120 ...  16  16  16]\n",
            " [ 13 217  44 ...  16  16  16]]\n",
            "[Valid 38/50]\t loss=2.877\t acc: 0.338\t perp: 17.765[[ 66   3  34 ...  16  16  16]\n",
            " [388  66  34 ...  16  16  16]\n",
            " [  3  34 131 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 323 ...  16  16  16]\n",
            " [372  80   3 ...  16  16  16]\n",
            " [123  44  50 ...  15  16  16]]\n",
            "[Valid 39/50]\t loss=2.880\t acc: 0.337\t perp: 17.819[[ 34 131  11 ...  16  16  16]\n",
            " [  3   3   3 ...  16  16  16]\n",
            " [ 86  46 110 ...  16  16  16]\n",
            " ...\n",
            " [135   3 396 ...  16  16  16]\n",
            " [ 21   3   3 ...  16  16  16]\n",
            " [ 13 101  19 ...  16  16  16]]\n",
            "[Valid 40/50]\t loss=2.879\t acc: 0.337\t perp: 17.804[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " ...\n",
            " [268  50 245 ...  16  16  16]\n",
            " [ 95 307   2 ...  16  16  16]\n",
            " [462   3   8 ...  16  16  16]]\n",
            "[Valid 41/50]\t loss=2.877\t acc: 0.338\t perp: 17.767[[366  44 520 ...  16  16  16]\n",
            " [268 214  44 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [  3 149 378 ...  16  16  16]\n",
            " [186  22  31 ...  16  16  16]\n",
            " [186 174   3 ...  16  16  16]]\n",
            "[Valid 42/50]\t loss=2.880\t acc: 0.337\t perp: 17.813[[  1  87   3 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [ 13   3  44 ...  16  16  16]\n",
            " ...\n",
            " [268 214   2 ...  16  16  16]\n",
            " [ 13 268 214 ...  16  16  16]\n",
            " [180 214  44 ...  16  16  16]]\n",
            "[Valid 43/50]\t loss=2.880\t acc: 0.337\t perp: 17.809[[  3 274  41 ...  16  16  16]\n",
            " [  3  19   3 ...  16  16  16]\n",
            " [585  46 281 ...  16  16  16]\n",
            " ...\n",
            " [ 73   1  44 ...  16  16  16]\n",
            " [309   2 251 ...  16  16  16]\n",
            " [309 253 254 ...  16  16  16]]\n",
            "[Valid 44/50]\t loss=2.879\t acc: 0.337\t perp: 17.791[[  1  44  87 ...  16  16  16]\n",
            " [  1 131   3 ...  16  16  16]\n",
            " [  1 164 134 ...  16  16  16]\n",
            " ...\n",
            " [192 590   3 ...  16  16  16]\n",
            " [ 22  46  34 ...  16  16  16]\n",
            " [189  22  46 ...  16  16  16]]\n",
            "[Valid 45/50]\t loss=2.880\t acc: 0.337\t perp: 17.817[[  1  60  92 ...  16  16  16]\n",
            " [139   2  92 ...  16  16  16]\n",
            " [309   2  92 ...  16  16  16]\n",
            " ...\n",
            " [ 95 323   2 ...  16  16  16]\n",
            " [ 95 323 164 ...  16  16  16]\n",
            " [ 22 144 137 ...  16  16  16]]\n",
            "[Valid 46/50]\t loss=2.880\t acc: 0.336\t perp: 17.821[[ 50   2   3 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 73  50  60 ...  16  16  16]\n",
            " ...\n",
            " [  3  44   3 ...  16  16  16]\n",
            " [110  34  44 ...  16  16  16]\n",
            " [110  34   6 ...  16  16  16]]\n",
            "[Valid 47/50]\t loss=2.879\t acc: 0.337\t perp: 17.802[[139   3  44 ...  16  16  16]\n",
            " [ 65   3   8 ...  16  16  16]\n",
            " [ 65  32 114 ...  16  16  16]\n",
            " ...\n",
            " [273 241  52 ...  16  16  16]\n",
            " [273 241   2 ...  16  16  16]\n",
            " [123  44   3 ...  16  16  16]]\n",
            "[Valid 48/50]\t loss=2.879\t acc: 0.337\t perp: 17.797[[101  19 204 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [  3 566 131 ...  16  16  16]\n",
            " ...\n",
            " [  1   2 269 ...  16  16  16]\n",
            " [  1  87  11 ...  16  16  16]\n",
            " [ 13  34  44 ...  16  16  16]]\n",
            "[Valid 49/50]\t loss=2.880\t acc: 0.337\t perp: 17.818[[101  19  80 ...  16  16  16]\n",
            " [101  19  73 ...  16  16  16]\n",
            " [  3  83 396 ...  16  16  16]\n",
            " ...\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]]\n",
            "[Valid 50/50]\t loss=2.877\t acc: 0.338\t perp: 17.765\n",
            "Model saved to ../rnn_model\n"
          ]
        }
      ],
      "source": [
        "## TODO: Increase epochs to a larger size when ready (maybe 2 or 3 would be enough?)\n",
        "!python assignment.py --type rnn --task train --data ../data/data.p --epochs 4 --chkpt_path ../rnn_model\n",
        "## if using colab, you may need to do something like the following or might need to %cd into the directory of interest first..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since this command also saves the model, we should be able to load it back in and use it. Feel free to modify the saving utility as needed based on your modifications, but the default system should work fine for the initial requirements. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model loaded from '../rnn_model'\n",
            "[[ 13  50  52 ...  16  16  16]\n",
            " [ 13 167  44 ...  16  16  16]\n",
            " [186 415  65 ...  16  16  16]\n",
            " ...\n",
            " [217 119 120 ...  16  16  16]\n",
            " [214 147   2 ...  16  16  16]\n",
            " [ 22 190 249 ...  16  16  16]]\n",
            "[Valid 1/50]\t loss=3.129\t acc: 0.313\t perp: 22.857[[214   2  92 ...  72  15  16]\n",
            " [ 17  79   2 ...  16  16  16]\n",
            " [ 17  79 157 ...  16  16  16]\n",
            " ...\n",
            " [  1   2  86 ...  16  16  16]\n",
            " [ 97   1   2 ...  16  16  16]\n",
            " [180   1  44 ...  16  16  16]]\n",
            "[Valid 2/50]\t loss=3.001\t acc: 0.323\t perp: 20.105[[ 86   1  44 ...  16  16  16]\n",
            " [  1   2  68 ...  16  16  16]\n",
            " [  1  11 461 ...  16  16  16]\n",
            " ...\n",
            " [462 421 558 ...  16  16  16]\n",
            " [ 13 307  44 ...  16  16  16]\n",
            " [462   2   3 ...  16  16  16]]\n",
            "[Valid 3/50]\t loss=2.979\t acc: 0.333\t perp: 19.659[[ 66  34 408 ...  16  16  16]\n",
            " [ 34  69   3 ...  16  16  16]\n",
            " [319 240  34 ...  16  16  16]\n",
            " ...\n",
            " [ 34   6  32 ...  16  16  16]\n",
            " [ 34 318   3 ...  16  16  16]\n",
            " [ 34  32  17 ...  16  16  16]]\n",
            "[Valid 4/50]\t loss=2.944\t acc: 0.332\t perp: 18.984[[147 138  65 ...  16  16  16]\n",
            " [532  44  60 ...  16  16  16]\n",
            " [436  65 424 ...  16  16  16]\n",
            " ...\n",
            " [ 17  79   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  73  79 ...  16  16  16]]\n",
            "[Valid 5/50]\t loss=2.931\t acc: 0.337\t perp: 18.739[[ 17  86 281 ...  16  16  16]\n",
            " [ 17  86 281 ...  96  11  15]\n",
            " [ 17  86 281 ...  16  16  16]\n",
            " ...\n",
            " [101  19 412 ...  16  16  16]\n",
            " [135 415 121 ...  16  16  16]\n",
            " [135 412 493 ...  16  16  16]]\n",
            "[Valid 6/50]\t loss=2.945\t acc: 0.339\t perp: 19.012[[ 37 159   3 ...  16  16  16]\n",
            " [ 37 208 415 ...  16  16  16]\n",
            " [ 37 337   1 ...  16  16  16]\n",
            " ...\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 95 307 221 ...  16  16  16]\n",
            " [ 28  50 221 ...  16  16  16]]\n",
            "[Valid 7/50]\t loss=2.927\t acc: 0.341\t perp: 18.680[[268  50   2 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  45 ...  16  16  16]\n",
            " ...\n",
            " [ 73 214  44 ...  16  16  16]\n",
            " [ 73 214   3 ...  16  16  16]\n",
            " [268 214  11 ...  16  16  16]]\n",
            "[Valid 8/50]\t loss=2.900\t acc: 0.343\t perp: 18.181[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 34  90 224 ...  16  16  16]\n",
            " ...\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]\n",
            " [  1 205  32 ...  16  16  16]]\n",
            "[Valid 9/50]\t loss=2.888\t acc: 0.343\t perp: 17.966[[123  24 186 ...  16  16  16]\n",
            " [186 121 147 ...  16  16  16]\n",
            " [186 127 559 ...  16  16  16]\n",
            " ...\n",
            " [ 17  23 282 ...  16  16  16]\n",
            " [ 17  23  60 ...  16  16  16]\n",
            " [ 17   3  24 ...  16  16  16]]\n",
            "[Valid 10/50]\t loss=2.877\t acc: 0.345\t perp: 17.754[[214   2  68 ...  16  16  16]\n",
            " [307   2 226 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " ...\n",
            " [309   3 224 ...  16  16  16]\n",
            " [309 367 120 ...  16  16  16]\n",
            " [ 13 309  44 ...  16  16  16]]\n",
            "[Valid 11/50]\t loss=2.872\t acc: 0.343\t perp: 17.673[[ 50 154 389 ...  16  16  16]\n",
            " [130  19 101 ...  16  16  16]\n",
            " [ 13 370  46 ...  16  16  16]\n",
            " ...\n",
            " [101  19  23 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [ 23   2   3 ...  16  16  16]]\n",
            "[Valid 12/50]\t loss=2.883\t acc: 0.341\t perp: 17.872[[ 34  32  13 ...  16  16  16]\n",
            " [268  34  11 ...  16  16  16]\n",
            " [ 95  34  11 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 193 ...  16  16  16]\n",
            " [ 50   3  51 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]]\n",
            "[Valid 13/50]\t loss=2.895\t acc: 0.339\t perp: 18.078[[  3   3  40 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " ...\n",
            " [101  19  22 ...  16  16  16]\n",
            " [  3  71  22 ...  16  16  16]\n",
            " [  3   3 537 ...  16  16  16]]\n",
            "[Valid 14/50]\t loss=2.892\t acc: 0.340\t perp: 18.026[[192   3 104 ...  16  16  16]\n",
            " [  1  60  61 ...  16  16  16]\n",
            " [500 214   3 ...  16  16  16]\n",
            " ...\n",
            " [186  80 289 ...  16  16  16]\n",
            " [186  83 289 ...  16  16  16]\n",
            " [186 268  83 ...  16  16  16]]\n",
            "[Valid 15/50]\t loss=2.887\t acc: 0.340\t perp: 17.936[[214   2  61 ...  16  16  16]\n",
            " [214 227 215 ...  16  16  16]\n",
            " [366   2  61 ...  16  16  16]\n",
            " ...\n",
            " [217  90   3 ...  16  16  16]\n",
            " [217 367   3 ...  16  16  16]\n",
            " [217  96 171 ...  16  16  16]]\n",
            "[Valid 16/50]\t loss=2.887\t acc: 0.340\t perp: 17.933[[101  19 281 ...  16  16  16]\n",
            " [  3  19 281 ...  16  16  16]\n",
            " [135 281  24 ...  16  16  16]\n",
            " ...\n",
            " [101  19 404 ...  16  16  16]\n",
            " [240 101  19 ...  16  16  16]\n",
            " [  3 599   3 ...  16  16  16]]\n",
            "[Valid 17/50]\t loss=2.889\t acc: 0.340\t perp: 17.983[[ 17  79  24 ...  16  16  16]\n",
            " [ 17  79  24 ...  16  16  16]\n",
            " [ 17 204  96 ...  16  16  16]\n",
            " ...\n",
            " [  1  44   3 ...  16  16  16]\n",
            " [139  44 467 ...  16  16  16]\n",
            " [139   3 487 ...  16  16  16]]\n",
            "[Valid 18/50]\t loss=2.891\t acc: 0.340\t perp: 18.009[[267  86  46 ...  16  16  16]\n",
            " [ 66  34  44 ...  16  16  16]\n",
            " [ 66  34  93 ...  16  16  16]\n",
            " ...\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]\n",
            " [ 17  22  31 ...  16  16  16]]\n",
            "[Valid 19/50]\t loss=2.889\t acc: 0.340\t perp: 17.983[[ 50  44 134 ...  16  16  16]\n",
            " [268  50  44 ...  16  16  16]\n",
            " [268  50  11 ... 143 472  15]\n",
            " ...\n",
            " [186  22   3 ...  16  16  16]\n",
            " [ 17  22 201 ...  16  16  16]\n",
            " [ 17 127  46 ...  16  16  16]]\n",
            "[Valid 20/50]\t loss=2.891\t acc: 0.338\t perp: 18.018[[  1  46 215 ...  16  16  16]\n",
            " [  1 119 189 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [339 307  44 ...  16  16  16]\n",
            " [ 73 214  87 ...  16  16  16]\n",
            " [ 73 214 131 ...  16  16  16]]\n",
            "[Valid 21/50]\t loss=2.889\t acc: 0.338\t perp: 17.972[[  1   2 240 ...  16  16  16]\n",
            " [  1   2  48 ...  16  16  16]\n",
            " [  1  69   3 ...  16  16  16]\n",
            " ...\n",
            " [186  22  24 ...  16  16  16]\n",
            " [186  22  24 ... 457  15  16]\n",
            " [186  22   2 ...  16  16  16]]\n",
            "[Valid 22/50]\t loss=2.888\t acc: 0.339\t perp: 17.960[[ 34  52 237 ...  16  16  16]\n",
            " [ 34  32 351 ...  16  16  16]\n",
            " [ 34 279  32 ...  16  16  16]\n",
            " ...\n",
            " [ 95 214   2 ...  16  16  16]\n",
            " [268 214   2 ...  16  16  16]\n",
            " [123  44 268 ...  16  16  16]]\n",
            "[Valid 23/50]\t loss=2.890\t acc: 0.338\t perp: 17.997[[135   3 289 ...  16  16  16]\n",
            " [135   3  32 ...  16  16  16]\n",
            " [ 13 135   3 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 95  50   3 ...  16  16  16]\n",
            " [ 13  50   2 ...  16  16  16]]\n",
            "[Valid 24/50]\t loss=2.895\t acc: 0.338\t perp: 18.080[[  1   3  11 ...  16  16  16]\n",
            " [  1   3  40 ...  16  16  16]\n",
            " [  1   2  86 ...  16  16  16]\n",
            " ...\n",
            " [ 17 267 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]\n",
            " [ 17 281   2 ...  16  16  16]]\n",
            "[Valid 25/50]\t loss=2.890\t acc: 0.338\t perp: 17.992[[  1  47 248 ...  16  16  16]\n",
            " [217 119   3 ...  16  16  16]\n",
            " [217  44 227 ...  16  16  16]\n",
            " ...\n",
            " [214   2 153 ...  16  16  16]\n",
            " [307  84 142 ...  16  16  16]\n",
            " [ 73 214 495 ...  16  16  16]]\n",
            "[Valid 26/50]\t loss=2.886\t acc: 0.339\t perp: 17.922[[  1  44   3 ...  16  16  16]\n",
            " [  1 408  32 ...  16  16  16]\n",
            " [  1 205   2 ...  16  16  16]\n",
            " ...\n",
            " [440 361   3 ...  16  16  16]\n",
            " [366 365 120 ...  16  16  16]\n",
            " [549 214  32 ...  16  16  16]]\n",
            "[Valid 27/50]\t loss=2.892\t acc: 0.338\t perp: 18.029[[101  19 121 ...  16  16  16]\n",
            " [  3  60  62 ...  16  16  16]\n",
            " [ 99   3   2 ...  16  16  16]\n",
            " ...\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17 404   3 ...  16  16  16]\n",
            " [ 17   3  19 ...  16  16  16]]\n",
            "[Valid 28/50]\t loss=2.898\t acc: 0.336\t perp: 18.141[[323  19  22 ...  16  16  16]\n",
            " [101  19  22 ...  16  16  16]\n",
            " [ 65  44 205 ...  16  16  16]\n",
            " ...\n",
            " [214  46 240 ...  16  16  16]\n",
            " [214  46  40 ...  16  16  16]\n",
            " [214   2  68 ...  16  16  16]]\n",
            "[Valid 29/50]\t loss=2.900\t acc: 0.336\t perp: 18.166[[ 50   2  61 ...  16  16  16]\n",
            " [ 50   2 200 ...  16  16  16]\n",
            " [ 50  44  96 ...  16  16  16]\n",
            " ...\n",
            " [240  86  34 ...  16  16  16]\n",
            " [ 95  86  46 ...  16  16  16]\n",
            " [ 86  34   3 ...  16  16  16]]\n",
            "[Valid 30/50]\t loss=2.886\t acc: 0.339\t perp: 17.928[[186  80   2 ...  16  16  16]\n",
            " [186  80   2 ...  16  16  16]\n",
            " [186  80 125 ...  16  16  16]\n",
            " ...\n",
            " [ 48 493  50 ...  16  16  16]\n",
            " [ 73  50  11 ...  16  16  16]\n",
            " [ 73  48 493 ...  16  16  16]]\n",
            "[Valid 31/50]\t loss=2.892\t acc: 0.337\t perp: 18.024[[214   3  54 ...  16  16  16]\n",
            " [242 217  44 ...  16  16  16]\n",
            " [  1 365 185 ...  16  16  16]\n",
            " ...\n",
            " [186 281   3 ...  16  16  16]\n",
            " [186 281 279 ...  16  16  16]\n",
            " [186 240 281 ...  16  16  16]]\n",
            "[Valid 32/50]\t loss=2.895\t acc: 0.336\t perp: 18.089[[ 34   3   3 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " [ 68  34 572 ...  16  16  16]\n",
            " ...\n",
            " [268  50   3 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 33/50]\t loss=2.893\t acc: 0.336\t perp: 18.048[[ 17 415  80 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " [ 17  80   3 ...  16  16  16]\n",
            " ...\n",
            " [  1  45   3 ...  16  16  16]\n",
            " [  1  41   3 ...  16  16  16]\n",
            " [ 13   3   1 ...  16  16  16]]\n",
            "[Valid 34/50]\t loss=2.884\t acc: 0.337\t perp: 17.881[[214   2 114 ...  16  16  16]\n",
            " [ 95 214   3 ...  16  16  16]\n",
            " [ 73 214  32 ...  16  16  16]\n",
            " ...\n",
            " [ 34  96   8 ...  16  16  16]\n",
            " [ 13  86  46 ...  94  15  16]\n",
            " [ 13  34  93 ...  16  16  16]]\n",
            "[Valid 35/50]\t loss=2.883\t acc: 0.337\t perp: 17.877[[214 270 608 ...  16  16  16]\n",
            " [ 73 214 270 ...  16  16  16]\n",
            " [307  11 354 ...  16  16  16]\n",
            " ...\n",
            " [ 50  69  47 ...  16  16  16]\n",
            " [268  50  87 ...  16  16  16]\n",
            " [ 13 268  50 ...  16  16  16]]\n",
            "[Valid 36/50]\t loss=2.880\t acc: 0.338\t perp: 17.806[[214   2  92 ...  16  16  16]\n",
            " [214  41  36 ...  16  16  16]\n",
            " [214  60 293 ...  16  16  16]\n",
            " ...\n",
            " [  1  46  65 ...  16  16  16]\n",
            " [ 17  22 320 ...  16  16  16]\n",
            " [ 17  22   3 ...  16  16  16]]\n",
            "[Valid 37/50]\t loss=2.880\t acc: 0.337\t perp: 17.822[[214   2  61 ...  16  16  16]\n",
            " [307  60  61 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [217   2  13 ...  16  16  16]\n",
            " [217 365 120 ...  16  16  16]\n",
            " [ 13 217  44 ...  16  16  16]]\n",
            "[Valid 38/50]\t loss=2.877\t acc: 0.338\t perp: 17.765[[ 66   3  34 ...  16  16  16]\n",
            " [388  66  34 ...  16  16  16]\n",
            " [  3  34 131 ...  16  16  16]\n",
            " ...\n",
            " [ 50   2 323 ...  16  16  16]\n",
            " [372  80   3 ...  16  16  16]\n",
            " [123  44  50 ...  15  16  16]]\n",
            "[Valid 39/50]\t loss=2.880\t acc: 0.337\t perp: 17.819[[ 34 131  11 ...  16  16  16]\n",
            " [  3   3   3 ...  16  16  16]\n",
            " [ 86  46 110 ...  16  16  16]\n",
            " ...\n",
            " [135   3 396 ...  16  16  16]\n",
            " [ 21   3   3 ...  16  16  16]\n",
            " [ 13 101  19 ...  16  16  16]]\n",
            "[Valid 40/50]\t loss=2.879\t acc: 0.337\t perp: 17.804[[ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " [ 86  46  68 ...  16  16  16]\n",
            " ...\n",
            " [268  50 245 ...  16  16  16]\n",
            " [ 95 307   2 ...  16  16  16]\n",
            " [462   3   8 ...  16  16  16]]\n",
            "[Valid 41/50]\t loss=2.877\t acc: 0.338\t perp: 17.767[[366  44 520 ...  16  16  16]\n",
            " [268 214  44 ...  16  16  16]\n",
            " [ 95 214  60 ...  16  16  16]\n",
            " ...\n",
            " [  3 149 378 ...  16  16  16]\n",
            " [186  22  31 ...  16  16  16]\n",
            " [186 174   3 ...  16  16  16]]\n",
            "[Valid 42/50]\t loss=2.880\t acc: 0.337\t perp: 17.813[[  1  87   3 ...  16  16  16]\n",
            " [  1 147   2 ...  16  16  16]\n",
            " [ 13   3  44 ...  16  16  16]\n",
            " ...\n",
            " [268 214   2 ...  16  16  16]\n",
            " [ 13 268 214 ...  16  16  16]\n",
            " [180 214  44 ...  16  16  16]]\n",
            "[Valid 43/50]\t loss=2.880\t acc: 0.337\t perp: 17.809[[  3 274  41 ...  16  16  16]\n",
            " [  3  19   3 ...  16  16  16]\n",
            " [585  46 281 ...  16  16  16]\n",
            " ...\n",
            " [ 73   1  44 ...  16  16  16]\n",
            " [309   2 251 ...  16  16  16]\n",
            " [309 253 254 ...  16  16  16]]\n",
            "[Valid 44/50]\t loss=2.879\t acc: 0.337\t perp: 17.791[[  1  44  87 ...  16  16  16]\n",
            " [  1 131   3 ...  16  16  16]\n",
            " [  1 164 134 ...  16  16  16]\n",
            " ...\n",
            " [192 590   3 ...  16  16  16]\n",
            " [ 22  46  34 ...  16  16  16]\n",
            " [189  22  46 ...  16  16  16]]\n",
            "[Valid 45/50]\t loss=2.880\t acc: 0.337\t perp: 17.817[[  1  60  92 ...  16  16  16]\n",
            " [139   2  92 ...  16  16  16]\n",
            " [309   2  92 ...  16  16  16]\n",
            " ...\n",
            " [ 95 323   2 ...  16  16  16]\n",
            " [ 95 323 164 ...  16  16  16]\n",
            " [ 22 144 137 ...  16  16  16]]\n",
            "[Valid 46/50]\t loss=2.880\t acc: 0.336\t perp: 17.821[[ 50   2   3 ...  16  16  16]\n",
            " [268  50   2 ...  16  16  16]\n",
            " [ 73  50  60 ...  16  16  16]\n",
            " ...\n",
            " [  3  44   3 ...  16  16  16]\n",
            " [110  34  44 ...  16  16  16]\n",
            " [110  34   6 ...  16  16  16]]\n",
            "[Valid 47/50]\t loss=2.879\t acc: 0.337\t perp: 17.802[[139   3  44 ...  16  16  16]\n",
            " [ 65   3   8 ...  16  16  16]\n",
            " [ 65  32 114 ...  16  16  16]\n",
            " ...\n",
            " [273 241  52 ...  16  16  16]\n",
            " [273 241   2 ...  16  16  16]\n",
            " [123  44   3 ...  16  16  16]]\n",
            "[Valid 48/50]\t loss=2.879\t acc: 0.337\t perp: 17.797[[101  19 204 ...  16  16  16]\n",
            " [101  19  23 ...  16  16  16]\n",
            " [  3 566 131 ...  16  16  16]\n",
            " ...\n",
            " [  1   2 269 ...  16  16  16]\n",
            " [  1  87  11 ...  16  16  16]\n",
            " [ 13  34  44 ...  16  16  16]]\n",
            "[Valid 49/50]\t loss=2.880\t acc: 0.337\t perp: 17.818[[101  19  80 ...  16  16  16]\n",
            " [101  19  73 ...  16  16  16]\n",
            " [  3  83 396 ...  16  16  16]\n",
            " ...\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17  66 281 ...  16  16  16]\n",
            " [ 17 281  24 ...  16  16  16]]\n",
            "[Valid 50/50]\t loss=2.877\t acc: 0.338\t perp: 17.765\n"
          ]
        }
      ],
      "source": [
        "!python assignment.py --type rnn --task test --data ../data/data.p --chkpt_path ../rnn_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvWXYsyQ0iIp"
      },
      "source": [
        "### Running your Transformer model\n",
        "\n",
        "Once you have completed the `transformer.py` file, run this block to train your transformer based model. Note that running with the `both` task will both train, save, and test your model in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xDXL5-huovlE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/noracai/Documents/CS1470/homework-5p-image-captioning-norafk/code/assignment.py\", line 171, in <module>\n",
            "    main(parse_args())\n",
            "  File \"/Users/noracai/Documents/CS1470/homework-5p-image-captioning-norafk/code/assignment.py\", line 76, in main\n",
            "    train_model(\n",
            "  File \"/Users/noracai/Documents/CS1470/homework-5p-image-captioning-norafk/code/assignment.py\", line 149, in train_model\n",
            "    stats += [model.train(captions, img_feats, pad_idx, batch_size=args.batch_size)]\n",
            "  File \"/Users/noracai/Documents/CS1470/homework-5p-image-captioning-norafk/code/model.py\", line 59, in train\n",
            "    loss = self.loss_function(probs, decoder_labels, mask)\n",
            "  File \"/Users/noracai/Documents/CS1470/homework-5p-image-captioning-norafk/code/model.py\", line 181, in loss_function\n",
            "    masked_prbs = tf.boolean_mask(prbs, mask)\n",
            "  File \"/Users/noracai/anaconda3/envs/csci1470/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/Users/noracai/anaconda3/envs/csci1470/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n",
            "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
            "ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n"
          ]
        }
      ],
      "source": [
        "## TODO: Increase epochs to a larger size when ready (maybe 2 or 3 would be enough?)\n",
        "!python assignment.py --type transformer --task both --data ../data/data.p --epochs 4 --lr 0.0005 --chkpt_path ../transform_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should be able to reach validation perplexity in the ballpark of 15-18 by the end of training! We found that around 4 epochs was enough for our settings, but your results may vary. Though you are not constrained by any time limits, know when to stop and try to be proactive with your time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71_bkKyU0iIq"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "After training our Transformer model, you can visualize the self-attention layer to examine the behavior of your attention heads and see if any patterns emerge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpz85avktKxt"
      },
      "source": [
        "To test out the components of the model interactively, you'll need to deconstruct selections of the model/runner code and get an instance of the model in an interactive context (aka inside the notebook). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at ../transform_model",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m args \u001b[38;5;241m=\u001b[39m parse_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--type rnn --task both --data ../data/data.p\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m     13\u001b[0m args\u001b[38;5;241m.\u001b[39mchkpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../transform_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m tra_imcap \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m args\u001b[38;5;241m.\u001b[39mchkpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../rnn_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m rnn_imcap \u001b[38;5;241m=\u001b[39m load_model(args)\n",
            "File \u001b[0;32m~/Documents/CS1470/homework-5p-image-captioning-norafk/code/assignment.py:108\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(args):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Loads model by reference based on arguments. Also returns said model'''\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchkpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAttentionHead\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttentionHead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAttentionMatrix\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttentionMatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mMultiHeadedAttention\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHeadedAttention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mTransformerBlock\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformerBlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mPositionalEncoding\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPositionalEncoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mTransformerDecoder\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTransformerDecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mRNNDecoder\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRNNDecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mImageCaptionModel\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mImageCaptionModel\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m## Saving is very nuanced. Might need to set the custom components correctly.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m## Functools.partial is a function wrapper that auto-fills a selection of arguments. \u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m## so in other words, the first argument of ImageCaptionModel.test is model (for self)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n",
            "File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at ../transform_model"
          ]
        }
      ],
      "source": [
        "## Feel free to insert auto-reloads as necessary\n",
        "from assignment import parse_args, load_model\n",
        "from decoder import TransformerDecoder, RNNDecoder\n",
        "\n",
        "## Pull your model into the notebook. This is heavily based off of assignment.py, \n",
        "## and feel free to reuse as much as you want. Your final project will probably \n",
        "## involve a lot of this investigative reverse-engineering based on what repos \n",
        "## you have to stumble upon.\n",
        "## You're not in a notebook scenario, so use get_default_arguments and feel free to update it...\n",
        "\n",
        "args = parse_args('--type rnn --task both --data ../data/data.p'.split())\n",
        "\n",
        "args.chkpt_path = '../transform_model'\n",
        "tra_imcap = load_model(args)\n",
        "\n",
        "args.chkpt_path = '../rnn_model'\n",
        "rnn_imcap = load_model(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnn_imcap.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tra_imcap.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our model, we need to be able to actually access the attention matrix that gets generated by out model. So that we can visualize it, right? Unfortunately for us, some convenience methods that allow you to make arbitrary model slices (i.e. the Functional API) are forfeit since our model is a subclass (in contrast to a sequential or functional). \n",
        "\n",
        "However, we can still dig into the model and force out way to computing the components we want. Our weights have been saved, after all..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yChcaClyump_"
      },
      "source": [
        "The following block of code visualizes the decoder self-attention for a random images in the test dataset. \n",
        "\n",
        "\n",
        "Move your mouse over the words in the left hand column, and see how much attention your decoder self-attention layer pays to each word in the sentance as it encodes each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y4cKlpWvwUf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from vis_utils import plot_decoder_text_attention\n",
        "import numpy as np\n",
        "\n",
        "index = np.random.choice(np.array(list(range(0,500,5))))\n",
        "\n",
        "caption    = test_captions[index][:-1]\n",
        "image_feat = test_img_feats[index]\n",
        "image      = test_images[index]\n",
        "\n",
        "print(\"Image number:\", index)\n",
        "\n",
        "def get_attention(tra_imcap, image_feat, caption):\n",
        "    ## TODO: If you're implementing multi-headed attension, you may need to change \n",
        "    ## some stuff to display to display all of the attention matrices.\n",
        "\n",
        "    ## Into impac decoder (NOTE: expand_dims only necessary for Transformer)\n",
        "    encoded_images = tra_imcap.decoder.image_embedding(tf.expand_dims(image_feat, 1))\n",
        "    # captions = tra_imcap.decoder.embedding(caption)\n",
        "    captions = tra_imcap.decoder.encoding(caption)\n",
        "    ## Into imcap TransformerBlock; get self-attention\n",
        "    AttentionHead = tra_imcap.decoder.decoder.self_atten\n",
        "    K = tf.tensordot(captions, AttentionHead.K, 1)\n",
        "    V = tf.tensordot(captions, AttentionHead.V, 1)\n",
        "    self_atten = AttentionHead.attn_mtx((K, V))\n",
        "    ## Into imcap TransformerBlock; get context self-attention\n",
        "    AttentionHead = tra_imcap.decoder.decoder.self_context_atten\n",
        "    K = tf.tensordot(captions, AttentionHead.K, 1)\n",
        "    V = tf.tensordot(captions, AttentionHead.V, 1)\n",
        "    self_context_atten = AttentionHead.attn_mtx((K, V))\n",
        "    return self_atten, self_context_atten\n",
        "\n",
        "\n",
        "def vis_attention(atten_mtx, image_features, caption, idx2word):\n",
        "    caption_words = [idx2word[idx] for idx in caption]\n",
        "    end_sentance_index = caption_words.index('<end>') if '<end>' in caption_words else 20\n",
        "    caption_words = caption_words[:end_sentance_index]\n",
        "    AttentionMatrix = atten_mtx[:, :end_sentance_index, :end_sentance_index]\n",
        "    AttentionMatrix = tf.reshape(AttentionMatrix, (1, 1, 1, end_sentance_index, end_sentance_index))\n",
        "    plot_decoder_text_attention(attention=AttentionMatrix, tokens=caption_words)\n",
        "\n",
        "self_atten, self_context_atten = get_attention(\n",
        "    tra_imcap, tf.expand_dims(image_feat, 0), tf.expand_dims(caption, 0)\n",
        ")\n",
        "\n",
        "print(\"self_atten\")\n",
        "vis_attention(self_atten, image_feat, caption, idx2word)\n",
        "\n",
        "print(\"self_context_atten\")\n",
        "vis_attention(self_context_atten, image_feat, caption, idx2word)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTYAclU7ALb"
      },
      "source": [
        "### Caption Generation\n",
        "Now that you have trained both of your models, it's time to use them to generate original captions for images in the testing set. First, the model is given the <start\\> token and asked to generate probabilites for the next word in the sequence. The next token is chosen by sampling from that probability. This process repeats until the model generates the <end\\> token, or the maximum sequence length is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zar8W0Zn7Lnr"
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "\n",
        "There is still one piece of this equation missing. The tokens are sampled from the probabilities your models generate, but your models were required to output logits, not probabilities. This is becasue this assignment, like many NLP models, uses temperature as a parameter in text generation. If the models sampled from  probabilies calculated by simply applying softmax to the logits, then the probability of the most likely word will usually be very high and the models will usually genrate the same, most probable caption every time. We use the temperature as a parameter to even out the probabilites so the model produces more 'creative' captions. This is done by dividing the logits by the temperature parameter before applying softmax. Higher temprature values will give a more creative captiong, while temprature values closer to 0 will be more greedy. Check out [this](https://lukesalamone.github.io/posts/what-is-temperature/) article for a demonstration and further explaination of temprature in NLP models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVNzx9-qP_Th"
      },
      "source": [
        "The following blocks of code will generate a caption for the image currently selected for the attention visualization above. Try playing around with different temperature values and see how it changes the captions your models generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_DpuFiYMOIa"
      },
      "outputs": [],
      "source": [
        "def gen_caption_temperature(model, image_embedding, wordToIds, padID, temp, window_length):\n",
        "    \"\"\"\n",
        "    Function used to generate a caption using an ImageCaptionModel given\n",
        "    an image embedding. \n",
        "    \"\"\"\n",
        "    idsToWords = {id: word for word, id in wordToIds.items()}\n",
        "    unk_token = wordToIds['<unk>']\n",
        "    caption_so_far = [wordToIds['<start>']]\n",
        "    while len(caption_so_far) < window_length and caption_so_far[-1] != wordToIds['<end>']:\n",
        "        caption_input = np.array([caption_so_far + ((window_length - len(caption_so_far)) * [padID])])\n",
        "        logits = model(np.expand_dims(image_embedding, 0), caption_input)\n",
        "        logits = logits[0][len(caption_so_far) - 1]\n",
        "        probs = tf.nn.softmax(logits / temp).numpy()\n",
        "        next_token = unk_token\n",
        "        attempts = 0\n",
        "        while next_token == unk_token and attempts < 5:\n",
        "            next_token = np.random.choice(len(probs), p=probs)\n",
        "            attempts += 1\n",
        "        caption_so_far.append(next_token)\n",
        "    return ' '.join([idsToWords[x] for x in caption_so_far][1:-1])\n",
        "\n",
        "temperature = .05\n",
        "gen_caption_temperature(tra_imcap, image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NNogJ5TL_-v"
      },
      "outputs": [],
      "source": [
        "temperature = 0.2\n",
        "gen_caption_temperature(tra_imcap, image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NOTE:** You may want to try a different image. Sometimes you get really unlucky with random selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Sentences for Training Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temperature = 0.05\n",
        "indices = np.random.choice(np.array(list(range(0, 500, 5))), 10, replace=False)\n",
        "for i in indices:\n",
        "    curr_image_feat = train_img_feats[i]\n",
        "    curr_image      = train_images[i]\n",
        "    for j in range(5):  ## Display all of the captions trained on\n",
        "        words = [idx2word[x] for x in train_captions[i+j][:-1] if idx2word[x] not in ('<pad>', '<start>', '<end>')]\n",
        "        print(f'C{j+1}:', ' '.join(words))\n",
        "    print('RNN:', gen_caption_temperature(rnn_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    print('TRA:', gen_caption_temperature(tra_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    plt.imshow(curr_image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trying out on things in testing set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temperature = 0.05\n",
        "indices = np.random.choice(np.array(list(range(0, 500, 5))), 10, replace=False)\n",
        "for i in indices:\n",
        "    curr_image_feat = test_img_feats[i]\n",
        "    curr_image      = test_images[i]\n",
        "    for j in range(5):  ## Display all of the captions trained on\n",
        "        words = [idx2word[x] for x in test_captions[i+j][:-1] if idx2word[x] not in ('<pad>', '<start>', '<end>')]\n",
        "        print(f'C{j+1}:', ' '.join(words))\n",
        "    print('RNN:', gen_caption_temperature(rnn_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    print('TRA:', gen_caption_temperature(tra_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    plt.imshow(curr_image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpwoQazfkfv1"
      },
      "source": [
        "# Conclusion!\n",
        "Congrats! You have finished this assignment! Below, put down your favorite captions that your RNN and Transformer models both generated!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n-1aiQFliGn"
      },
      "outputs": [],
      "source": [
        "## TODO: fill in the ? and display the vis images with the generated caption below it\n",
        "\n",
        "rnn_image_index = 42#?\n",
        "rnn_caption = gen_caption_temperature(rnn_imcap, test_img_feats[rnn_image_index], word2idx, word2idx['<pad>'], temperature, args.window_size)\n",
        "\n",
        "tra_image_index = 23#?\n",
        "tra_caption = gen_caption_temperature(tra_imcap, test_img_feats[tra_image_index], word2idx, word2idx['<pad>'], temperature, args.window_size)\n",
        "\n",
        "print(rnn_caption)\n",
        "plt.imshow(test_images[rnn_image_index])\n",
        "plt.show()\n",
        "\n",
        "print(tra_caption)\n",
        "plt.imshow(test_images[tra_image_index])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "im_cap_notebook.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('dl3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "895b6b526044b58cdb0796603b6137eb4df401700b6bb2bfb9582034a97581c4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
